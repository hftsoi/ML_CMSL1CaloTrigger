{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder Training for Anomaly Detection @ L1Trigger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "import keras_tuner\n",
    "from keras_tuner import Hyperband\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input files reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All input files are already sorted in Calo regions (i, j) ~ (18, 14)<br>\n",
    "Where i = 0 -> 17 corresponds to GCT_Phi = 0 -> 17<br>\n",
    "Where j = 0 -> 13 corresponds to RCT_Eta = 4 -> 17\n",
    "\n",
    "Keep this ordering as is when feeding into neural nets. Also keep this in mind when generating/preparing new samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zerobias and MC signal files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZeroBias shape: (500000, 18, 14, 3)\n",
      "i = 0: (500000, 18, 14, 3)\n",
      "i = 1: (500000, 18, 14, 3)\n",
      "i = 2: (500000, 18, 14, 3)\n",
      "i = 3: (300000, 18, 14, 3)\n",
      "i = 4: (100000, 18, 14, 3)\n",
      "i = 5: (500000, 18, 14, 3)\n",
      "i = 6: (98600, 18, 14, 3)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "ZeroBiasA0 = h5py.File('bkg/ZeroBias2018RunA_0.h5', 'r')\n",
    "ZeroBiasA1 = h5py.File('bkg/ZeroBias2018RunA_1.h5', 'r')\n",
    "ZeroBiasA2 = h5py.File('bkg/ZeroBias2018RunA_2.h5', 'r')\n",
    "ZeroBiasA0 = np.stack((ZeroBiasA0['CaloRegions'][:].astype('float32'),\n",
    "                       (~ZeroBiasA0['ElectronBit'][:]+2).astype('float32'),\n",
    "                       (~ZeroBiasA0['TauBit'][:]+2).astype('float32')))\n",
    "ZeroBiasA1 = np.stack((ZeroBiasA1['CaloRegions'][:].astype('float32'),\n",
    "                       (~ZeroBiasA1['ElectronBit'][:]+2).astype('float32'),\n",
    "                       (~ZeroBiasA1['TauBit'][:]+2).astype('float32')))\n",
    "ZeroBiasA2 = np.stack((ZeroBiasA2['CaloRegions'][:].astype('float32'),\n",
    "                       (~ZeroBiasA2['ElectronBit'][:]+2).astype('float32'),\n",
    "                       (~ZeroBiasA2['TauBit'][:]+2).astype('float32')))\n",
    "ZeroBiasA0 = np.moveaxis(ZeroBiasA0, 0, -1)\n",
    "ZeroBiasA1 = np.moveaxis(ZeroBiasA1, 0, -1)\n",
    "ZeroBiasA2 = np.moveaxis(ZeroBiasA2, 0, -1)\n",
    "ZeroBiasA = np.concatenate((ZeroBiasA0, ZeroBiasA1, ZeroBiasA2))\n",
    "del ZeroBiasA0\n",
    "del ZeroBiasA1\n",
    "del ZeroBiasA2\n",
    "'''\n",
    "\n",
    "ZeroBias = h5py.File('bkg/EphemeralZeroBias2018RunD_1.h5', 'r')\n",
    "ZeroBias = np.stack((ZeroBias['CaloRegions'][:500000].astype('float32'),\n",
    "                     ZeroBias['EGBit'][:500000].astype('float32'),\n",
    "                     ZeroBias['TauBit'][:500000].astype('float32')))\n",
    "ZeroBias = np.moveaxis(ZeroBias, 0, -1)\n",
    "\n",
    "print('ZeroBias shape: ' + str(ZeroBias.shape))\n",
    "\n",
    "MC_files = []\n",
    "MC_files.append('bkg/110X/QCD_Pt-15to7000_TuneCP5_Flat_14TeV_0.h5')#i=0\n",
    "MC_files.append('bkg/120X/SingleNeutrino_E-10-gun_0.h5')#i=1\n",
    "MC_files.append('bkg/120X/SingleNeutrino_Pt-2To20-gun_0.h5')#i=2\n",
    "'''\n",
    "MC_files.append('sig/110X/GluGluToHHTo4B_node_SM_TuneCP5_14TeV.h5')#i=3\n",
    "MC_files.append('sig/110X/HTo2LongLivedTo4mu_MH-1000_MFF-450_CTau-10000mm_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/110X/HTo2LongLivedTo4mu_MH-125_MFF-12_CTau-900mm_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/110X/HTo2LongLivedTo4mu_MH-125_MFF-25_CTau-1500mm_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/110X/HTo2LongLivedTo4mu_MH-125_MFF-50_CTau-3000mm_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/110X/VBFHToTauTau_M125_TuneCUETP8M1_14TeV.h5')\n",
    "MC_files.append('sig/110X/VBF_HH_CV_1_C2V_1_C3_1_TuneCP5_PSweights_14TeV.h5')\n",
    "MC_files.append('sig/110X/VBF_HToInvisible_M125_TuneCUETP8M1_14TeV.h5')\n",
    "MC_files.append('sig/110X/VectorZPrimeToQQ_M100_pT300_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/110X/VectorZPrimeToQQ_M200_pT300_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/110X/VectorZPrimeToQQ_M50_pT300_TuneCP5_14TeV.h5')#i=13\n",
    "MC_files.append('sig/110X/ZprimeToZH_MZprime1000_MZ50_MH80_ZTouds_HTouds_narrow_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/110X/ZprimeToZH_MZprime600_MZ50_MH80_ZTouds_HTouds_narrow_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/110X/ZprimeToZH_MZprime800_MZ50_MH80_ZTouds_HTouds_narrow_TuneCP5_14TeV.h5')\n",
    "'''\n",
    "\n",
    "MC_files.append('sig/120X/GluGluHToTauTau_M-125_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/GluGluToHHTo4B_node_cHHH1_TuneCP5_14TeV.h5')\n",
    "'''\n",
    "MC_files.append('sig/120X/GluGluToHHTo4B_node_cHHH5_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/HTo2LongLivedTo4b_MH-1000_MFF-450_CTau-100000mm_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/HTo2LongLivedTo4b_MH-1000_MFF-450_CTau-10000mm_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/HTo2LongLivedTo4b_MH-125_MFF-12_CTau-9000mm_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/HTo2LongLivedTo4b_MH-125_MFF-12_CTau-900mm_TuneCP5_14TeV.h5')#i=23\n",
    "MC_files.append('sig/120X/HTo2LongLivedTo4b_MH-125_MFF-25_CTau-15000mm_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/HTo2LongLivedTo4b_MH-125_MFF-25_CTau-1500mm_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/HTo2LongLivedTo4b_MH-125_MFF-50_CTau-30000mm_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/HTo2LongLivedTo4b_MH-125_MFF-50_CTau-3000mm_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/HTo2LongLivedTo4b_MH-250_MFF-120_CTau-10000mm_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/HTo2LongLivedTo4b_MH-250_MFF-120_CTau-1000mm_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/HTo2LongLivedTo4b_MH-250_MFF-60_CTau-1000mm_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/HTo2LongLivedTo4b_MH-350_MFF-160_CTau-10000mm_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/HTo2LongLivedTo4b_MH-350_MFF-160_CTau-1000mm_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/HTo2LongLivedTo4b_MH-350_MFF-160_CTau-500mm_TuneCP5_14TeV.h5')#i=33\n",
    "MC_files.append('sig/120X/HTo2LongLivedTo4b_MH-350_MFF-80_CTau-10000mm_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/HTo2LongLivedTo4b_MH-350_MFF-80_CTau-1000mm_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/HTo2LongLivedTo4b_MH-350_MFF-80_CTau-500mm_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/HTo2LongLivedTo4mu_MH-1000_MFF-450_CTau-10000mm_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/HTo2LongLivedTo4mu_MH-125_MFF-12_CTau-900mm_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/HTo2LongLivedTo4mu_MH-125_MFF-25_CTau-1500mm_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/HTo2LongLivedTo4mu_MH-125_MFF-50_CTau-3000mm_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/SUSYGluGluToBBHToBB_NarrowWidth_M-1200_TuneCP5_13TeV-pythia814TeV.h5')\n",
    "MC_files.append('sig/120X/SUSYGluGluToBBHToBB_NarrowWidth_M-120_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/SUSYGluGluToBBHToBB_NarrowWidth_M-350_TuneCP5_14TeV.h5')#i=43\n",
    "MC_files.append('sig/120X/SUSYGluGluToBBHToBB_NarrowWidth_M-600_TuneCP5_14TeV.h5')\n",
    "'''\n",
    "MC_files.append('sig/120X/TT_TuneCP5_14TeV.h5')\n",
    "'''\n",
    "MC_files.append('sig/120X/TprimeBToTH_M-650_LH_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/VBFHHTo4B_CV_1_C2V_2_C3_1_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/VBFHToInvisible_M125_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/VBFHToTauTau_M125_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/VectorZPrimeGammaToQQGamma_M-10_GPt-75_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/VectorZPrimeToQQ_M-100_Pt-300_TuneCP5_14TeV.h5')\n",
    "MC_files.append('sig/120X/VectorZPrimeToQQ_M-200_Pt-300_TuneCP5_14TeV.h5')#i=52\n",
    "MC_files.append('sig/120X/emj-mMed-800-mDark-10-ctau-0p1.h5')\n",
    "MC_files.append('sig/120X/emj-mMed-800-mDark-10-ctau-1.h5')\n",
    "MC_files.append('sig/120X/emj-mMed-800-mDark-10-ctau-1000.h5')\n",
    "MC_files.append('sig/120X/emj-mMed-800-mDark-10-ctau-150.h5')\n",
    "'''\n",
    "MC_files.append('sig/120X/haa4b_ma15_powheg.h5')\n",
    "'''\n",
    "MC_files.append('sig/120X/haa4b_ma15_powheg_FlatPU0To80.h5')\n",
    "MC_files.append('sig/120X/haa4b_ma50_powheg.h5')\n",
    "MC_files.append('sig/120X/haa4taus_ma15_powheg.h5')\n",
    "'''\n",
    "\n",
    "MC = []\n",
    "for i in range(len(MC_files)):\n",
    "    MC.append(h5py.File(MC_files[i], 'r'))\n",
    "    MC[i] = np.stack((MC[i]['CaloRegions'][:500000].astype('float32'),\n",
    "                      MC[i]['EGBit'][:500000].astype('float32'),\n",
    "                      MC[i]['TauBit'][:500000].astype('float32')))\n",
    "    MC[i] = np.moveaxis(MC[i], 0, -1)\n",
    "    print('i = ' + str(i) + ': ' + str(MC[i].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See distributions of EG/Tau bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table_EGTau_FF = []\n",
    "table_EGTau_TF = []\n",
    "table_EGTau_FT = []\n",
    "table_EGTau_TT = []\n",
    "\n",
    "table_EGTau_FF_pt = []\n",
    "table_EGTau_TF_pt = []\n",
    "table_EGTau_FT_pt = []\n",
    "table_EGTau_TT_pt = []\n",
    "\n",
    "bits = []\n",
    "bits_pt = []\n",
    "for n in range(1000):\n",
    "    for i in range(18):\n",
    "        for j in range(14):\n",
    "            if ZeroBias[n,i,j,1]==0 and ZeroBias[n,i,j,2]==0:\n",
    "                bits.append(1)\n",
    "                if ZeroBias[n,i,j,0]>10:\n",
    "                    bits_pt.append(1)\n",
    "            if ZeroBias[n,i,j,1]==1 and ZeroBias[n,i,j,2]==0:\n",
    "                bits.append(2)\n",
    "                if ZeroBias[n,i,j,0]>10:\n",
    "                    bits_pt.append(2)\n",
    "            if ZeroBias[n,i,j,1]==0 and ZeroBias[n,i,j,2]==1:\n",
    "                bits.append(3)\n",
    "                if ZeroBias[n,i,j,0]>10:\n",
    "                    bits_pt.append(3)\n",
    "            if ZeroBias[n,i,j,1]==1 and ZeroBias[n,i,j,2]==1:\n",
    "                bits.append(4)\n",
    "                if ZeroBias[n,i,j,0]>10:\n",
    "                    bits_pt.append(4)\n",
    "                \n",
    "table_EGTau_FF.append(np.round(bits.count(1)/(len(bits))*100,5))\n",
    "table_EGTau_TF.append(np.round(bits.count(2)/(len(bits))*100,5))\n",
    "table_EGTau_FT.append(np.round(bits.count(3)/(len(bits))*100,5))\n",
    "table_EGTau_TT.append(np.round(bits.count(4)/(len(bits))*100,5))\n",
    "\n",
    "table_EGTau_FF_pt.append(np.round(bits_pt.count(1)/(len(bits))*100,5))\n",
    "table_EGTau_TF_pt.append(np.round(bits_pt.count(2)/(len(bits))*100,5))\n",
    "table_EGTau_FT_pt.append(np.round(bits_pt.count(3)/(len(bits))*100,5))\n",
    "table_EGTau_TT_pt.append(np.round(bits_pt.count(4)/(len(bits))*100,5))\n",
    "\n",
    "for k in range(len(MC_files)):\n",
    "    bits = []\n",
    "    bits_pt = []\n",
    "    for n in range(MC[k].shape[0]):\n",
    "        for i in range(18):\n",
    "            for j in range(14):\n",
    "                if MC[k][n,i,j,1]==0 and MC[k][n,i,j,2]==0:\n",
    "                    bits.append(1)\n",
    "                    if MC[k][n,i,j,0]>10:\n",
    "                        bits_pt.append(1)\n",
    "                if MC[k][n,i,j,1]==1 and MC[k][n,i,j,2]==0:\n",
    "                    bits.append(2)\n",
    "                    if MC[k][n,i,j,0]>10:\n",
    "                        bits_pt.append(2)\n",
    "                if MC[k][n,i,j,1]==0 and MC[k][n,i,j,2]==1:\n",
    "                    bits.append(3)\n",
    "                    if MC[k][n,i,j,0]>10:\n",
    "                        bits_pt.append(3)\n",
    "                if MC[k][n,i,j,1]==1 and MC[k][n,i,j,2]==1:\n",
    "                    bits.append(4)\n",
    "                    if MC[k][n,i,j,0]>10:\n",
    "                        bits_pt.append(4)\n",
    "    \n",
    "    table_EGTau_FF.append(np.round(bits.count(1)/(len(bits))*100,5))\n",
    "    table_EGTau_TF.append(np.round(bits.count(2)/(len(bits))*100,5))\n",
    "    table_EGTau_FT.append(np.round(bits.count(3)/(len(bits))*100,5))\n",
    "    table_EGTau_TT.append(np.round(bits.count(4)/(len(bits))*100,5))\n",
    "    \n",
    "    table_EGTau_FF_pt.append(np.round(bits_pt.count(1)/(len(bits))*100,5))\n",
    "    table_EGTau_TF_pt.append(np.round(bits_pt.count(2)/(len(bits))*100,5))\n",
    "    table_EGTau_FT_pt.append(np.round(bits_pt.count(3)/(len(bits))*100,5))\n",
    "    table_EGTau_TT_pt.append(np.round(bits_pt.count(4)/(len(bits))*100,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files_table=[]\n",
    "files_table.append('EphemeralZeroBias2018RunD')\n",
    "for i in range(len(MC_files)):\n",
    "    files_table.append(MC_files[i])\n",
    "\n",
    "table_EGTau = pd.DataFrame({'Both OFF': np.round(table_EGTau_FF,3),\n",
    "                            'EG-only': np.round(table_EGTau_TF,3),\n",
    "                            'Tau-only': np.round(table_EGTau_FT,3),\n",
    "                            'Both ON': np.round(table_EGTau_TT,3)},\n",
    "                            index = files_table)\n",
    "\n",
    "table_EGTau_pt = pd.DataFrame({'pt>10, Both OFF': np.round(table_EGTau_FF_pt,3),\n",
    "                               'pt>10, EG-only': np.round(table_EGTau_TF_pt,3),\n",
    "                               'pt>10, Tau-only': np.round(table_EGTau_FT_pt,3),\n",
    "                               'pt>10, Both ON': np.round(table_EGTau_TT_pt,3)},\n",
    "                               index = files_table)\n",
    "\n",
    "table_EG = pd.DataFrame({'EG OFF': np.round(table_EGTau_FF,2)+np.round(table_EGTau_FT,2),\n",
    "                         'EG ON': np.round(table_EGTau_TF,2)+np.round(table_EGTau_TT,2)},\n",
    "                         index = files_table)\n",
    "\n",
    "table_EG_pt = pd.DataFrame({'pt>10, EG OFF': np.round(table_EGTau_FF_pt,2)+np.round(table_EGTau_FT_pt,2),\n",
    "                            'pt>10, EG ON': np.round(table_EGTau_TF_pt,2)+np.round(table_EGTau_TT_pt,2)},\n",
    "                            index = files_table)\n",
    "\n",
    "table_Tau = pd.DataFrame({'Tau OFF': np.round(table_EGTau_FF,2)+np.round(table_EGTau_TF,2),\n",
    "                          'Tau ON': np.round(table_EGTau_FT,2)+np.round(table_EGTau_TT,2)},\n",
    "                          index = files_table)\n",
    "\n",
    "table_Tau_pt = pd.DataFrame({'pt>10, Tau OFF': np.round(table_EGTau_FF_pt,2)+np.round(table_EGTau_TF_pt,2),\n",
    "                             'pt>10, Tau ON': np.round(table_EGTau_FT_pt,2)+np.round(table_EGTau_TT_pt,2)},\n",
    "                             index = files_table)\n",
    "\n",
    "table_EGTau = table_EGTau.drop(index=[MC_files[0],MC_files[1],MC_files[2]])\n",
    "table_EGTau_pt = table_EGTau_pt.drop(index=[MC_files[0],MC_files[1],MC_files[2]])\n",
    "table_EG = table_EG.drop(index=[MC_files[0],MC_files[1],MC_files[2]])\n",
    "table_EG_pt = table_EG_pt.drop(index=[MC_files[0],MC_files[1],MC_files[2]])\n",
    "table_Tau = table_Tau.drop(index=[MC_files[0],MC_files[1],MC_files[2]])\n",
    "table_Tau_pt = table_Tau_pt.drop(index=[MC_files[0],MC_files[1],MC_files[2]])\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(table_EGTau)\n",
    "display(table_EGTau_pt)\n",
    "display(table_EG)\n",
    "display(table_EG_pt)\n",
    "display(table_Tau)\n",
    "display(table_Tau_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del table_EGTau_FF, table_EGTau_TF, table_EGTau_FT, table_EGTau_TT\n",
    "del table_EGTau_FF_pt, table_EGTau_TF_pt, table_EGTau_FT_pt, table_EGTau_TT_pt\n",
    "del bits, bits_pt\n",
    "del files_table, table_EGTau, table_EGTau_pt, table_EG, table_EG_pt, table_Tau, table_Tau_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@@@@ masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZeroBias_masked = np.empty(shape=ZeroBias.shape, dtype=int)\n",
    "ZeroBias_masked[:,:,:,0] = ZeroBias[:,:,:,0] * (1 - ZeroBias[:,:,:,1]) * (1 - ZeroBias[:,:,:,2])\n",
    "ZeroBias_masked[:,:,:,1] = ZeroBias[:,:,:,0] * ZeroBias[:,:,:,1]\n",
    "ZeroBias_masked[:,:,:,2] = ZeroBias[:,:,:,0] * ZeroBias[:,:,:,2]\n",
    "\n",
    "MC_masked = []\n",
    "for i in range(len(MC_files)):\n",
    "    MC_masked.append(np.empty(shape=MC[i].shape, dtype=int))\n",
    "    MC_masked[i][:,:,:,0] = MC[i][:,:,:,0] * (1 - MC[i][:,:,:,1]) * (1 - MC[i][:,:,:,2])\n",
    "    MC_masked[i][:,:,:,1] = MC[i][:,:,:,0] * MC[i][:,:,:,1]\n",
    "    MC_masked[i][:,:,:,2] = MC[i][:,:,:,0] * MC[i][:,:,:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Et and EG/Tau bits per event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n in range(1230,1231):\n",
    "    bits = np.empty(shape = (18,14,3), dtype = 'object')\n",
    "    for i in range(18):\n",
    "        for j in range(14):\n",
    "            if ZeroBias[n,i,j,0]==0:\n",
    "                bits[i,j,0] = ' '\n",
    "            if ZeroBias[n,i,j,0]>0:\n",
    "                bits[i,j,0] = ZeroBias[n,i,j,0].astype(int)\n",
    "            if ZeroBias[n,i,j,1]==0:\n",
    "                bits[i,j,1] = ' '\n",
    "            if ZeroBias[n,i,j,1]==1:\n",
    "                bits[i,j,1] = 'EG'\n",
    "            if ZeroBias[n,i,j,2]==0:\n",
    "                bits[i,j,2] = ' '\n",
    "            if ZeroBias[n,i,j,2]==1:\n",
    "                bits[i,j,2] = 'Tau'\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (18,18))\n",
    "    ax = plt.subplot(2, 2, 1)\n",
    "    ax = sns.heatmap(ZeroBias[n,:,:,0], vmin = 0, vmax = ZeroBias[n,:,:,0].max(), annot = bits[:,:,0], fmt = '', linewidths = 0.1, cmap = \"Blues\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title('EphemeralZeroBias2018RunD\\nAnnotation = Et (GeV)')\n",
    "\n",
    "    ax = plt.subplot(2, 2, 2)\n",
    "    ax = sns.heatmap(ZeroBias[n,:,:,0], vmin = 0, vmax = ZeroBias[n,:,:,0].max(), annot = bits[:,:,1], fmt = '', linewidths = 0.1, cmap = \"Blues\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title('EphemeralZeroBias2018RunD\\nAnnotation = EGamma bit (bool)')\n",
    "    \n",
    "    ax = plt.subplot(2, 2, 3)\n",
    "    ax = sns.heatmap(ZeroBias[n,:,:,0], vmin = 0, vmax = ZeroBias[n,:,:,0].max(), annot = bits[:,:,2], fmt = '', linewidths = 0.1, cmap = \"Blues\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title('EphemeralZeroBias2018RunD\\nAnnotation = Tau bit (bool)')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "del bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n in range(1233,1236):\n",
    "    mask = np.empty(shape = (18,14,3), dtype = 'object')\n",
    "    for i in range(18):\n",
    "        for j in range(14):\n",
    "            if ZeroBias_masked[n,i,j,0]==0:\n",
    "                mask[i,j,0] = ' '\n",
    "            if ZeroBias_masked[n,i,j,0]>0:\n",
    "                mask[i,j,0] = ZeroBias_masked[n,i,j,0]\n",
    "            if ZeroBias_masked[n,i,j,1]==0:\n",
    "                mask[i,j,1] = ' '\n",
    "            if ZeroBias_masked[n,i,j,1]>0:\n",
    "                mask[i,j,1] = ZeroBias_masked[n,i,j,1]\n",
    "            if ZeroBias_masked[n,i,j,2]==0:\n",
    "                mask[i,j,2] = ' '\n",
    "            if ZeroBias_masked[n,i,j,2]>0:\n",
    "                mask[i,j,2] = ZeroBias_masked[n,i,j,2]\n",
    "                \n",
    "    fig, ax = plt.subplots(figsize = (18,18))\n",
    "    ax = plt.subplot(2, 2, 1)\n",
    "    ax = sns.heatmap(ZeroBias_masked[n,:,:,0], vmin = 0, vmax = ZeroBias[n,:,:,0].max(), annot = mask[:,:,0], fmt = '', linewidths = 0.1, cmap = \"Blues\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title('EphemeralZeroBias2018RunD\\nAnnotation = Et without EG/Tau (GeV)')\n",
    "\n",
    "    ax = plt.subplot(2, 2, 2)\n",
    "    ax = sns.heatmap(ZeroBias_masked[n,:,:,1], vmin = 0, vmax = ZeroBias[n,:,:,0].max(), annot = mask[:,:,1], fmt = '', linewidths = 0.1, cmap = \"Blues\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title('EphemeralZeroBias2018RunD\\nAnnotation = Et with EGbit (GeV)')\n",
    "    \n",
    "    ax = plt.subplot(2, 2, 3)\n",
    "    ax = sns.heatmap(ZeroBias_masked[n,:,:,2], vmin = 0, vmax = ZeroBias[n,:,:,0].max(), annot = mask[:,:,2], fmt = '', linewidths = 0.1, cmap = \"Blues\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title('EphemeralZeroBias2018RunD\\nAnnotation = Et with Taubit (GeV)')\n",
    "    \n",
    "    plt.show()\n",
    "del mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k=4\n",
    "for n in range(193,194):\n",
    "    bits = np.empty(shape = (18,14,3), dtype = 'object')\n",
    "    for i in range(18):\n",
    "        for j in range(14):\n",
    "            if MC[k][n,i,j,0]==0:\n",
    "                bits[i,j,0] = ' '\n",
    "            if MC[k][n,i,j,0]>0:\n",
    "                bits[i,j,0] = MC[k][n,i,j,0].astype(int)\n",
    "            if MC[k][n,i,j,1]==0:\n",
    "                bits[i,j,1] = ' '\n",
    "            if MC[k][n,i,j,1]==1:\n",
    "                bits[i,j,1] = 'EG'\n",
    "            if MC[k][n,i,j,2]==0:\n",
    "                bits[i,j,2] = ' '\n",
    "            if MC[k][n,i,j,2]==1:\n",
    "                bits[i,j,2] = 'Tau'\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (18,18))\n",
    "    ax = plt.subplot(2, 2, 1)\n",
    "    ax = sns.heatmap(MC[k][n,:,:,0], vmin = 0, vmax = MC[k][n,:,:,0].max(), annot = bits[:,:,0], fmt = '', linewidths = 0.1, cmap = \"Greens\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title('{}\\nAnnotation = Et (GeV)'.format(MC_files[k]))\n",
    "\n",
    "    ax = plt.subplot(2, 2, 2)\n",
    "    ax = sns.heatmap(MC[k][n,:,:,0], vmin = 0, vmax = MC[k][n,:,:,0].max(), annot = bits[:,:,1], fmt = '', linewidths = 0.1, cmap = \"Greens\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title('{}\\nAnnotation = EGamma bit (bool)'.format(MC_files[k]))\n",
    "    \n",
    "    ax = plt.subplot(2, 2, 3)\n",
    "    ax = sns.heatmap(MC[k][n,:,:,0], vmin = 0, vmax = MC[k][n,:,:,0].max(), annot = bits[:,:,2], fmt = '', linewidths = 0.1, cmap = \"Greens\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title('{}\\nAnnotation = Tau bit (bool)'.format(MC_files[k]))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "del bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k=5\n",
    "for n in range(193,196):\n",
    "    mask = np.empty(shape = (18,14,3), dtype = 'object')\n",
    "    for i in range(18):\n",
    "        for j in range(14):\n",
    "            if MC_masked[k][n,i,j,0]==0:\n",
    "                mask[i,j,0] = ' '\n",
    "            if MC_masked[k][n,i,j,0]>0:\n",
    "                mask[i,j,0] = MC_masked[k][n,i,j,0].astype(int)\n",
    "            if MC_masked[k][n,i,j,1]==0:\n",
    "                mask[i,j,1] = ' '\n",
    "            if MC_masked[k][n,i,j,1]>0:\n",
    "                mask[i,j,1] = MC_masked[k][n,i,j,1].astype(int)\n",
    "            if MC_masked[k][n,i,j,2]==0:\n",
    "                mask[i,j,2] = ' '\n",
    "            if MC_masked[k][n,i,j,2]>0:\n",
    "                mask[i,j,2] = MC_masked[k][n,i,j,2].astype(int)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (18,18))\n",
    "    ax = plt.subplot(2, 2, 1)\n",
    "    ax = sns.heatmap(MC_masked[k][n,:,:,0], vmin = 0, vmax = MC[k][n,:,:,0].max(), annot = mask[:,:,0], fmt = '', linewidths = 0.1, cmap = \"Greens\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title('{}\\nAnnotation = Et without EG/Tau (GeV)'.format(MC_files[k]))\n",
    "\n",
    "    ax = plt.subplot(2, 2, 2)\n",
    "    ax = sns.heatmap(MC_masked[k][n,:,:,1], vmin = 0, vmax = MC[k][n,:,:,0].max(), annot = mask[:,:,1], fmt = '', linewidths = 0.1, cmap = \"Greens\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title('{}\\nAnnotation = Et with EGbit (GeV)'.format(MC_files[k]))\n",
    "    \n",
    "    ax = plt.subplot(2, 2, 3)\n",
    "    ax = sns.heatmap(MC_masked[k][n,:,:,2], vmin = 0, vmax = MC[k][n,:,:,0].max(), annot = mask[:,:,2], fmt = '', linewidths = 0.1, cmap = \"Greens\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title('{}\\nAnnotation = Et with Taubit (GeV)'.format(MC_files[k]))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "del mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at some ZB statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZB_mean = np.mean(ZeroBias[:,:,:,0], axis = 0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "ax = plt.subplot(2, 2, 2)\n",
    "ax = sns.heatmap(ZB_mean.reshape(18, 14), vmin = 0, vmax = ZB_mean.max(), cmap = \"Blues\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.set_title('Mean Et distribution (EphemeralZeroBias2018RunD)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ZeroBias[:,:,:,0].reshape((-1)), bins = 20, log = True)\n",
    "plt.xlabel(\"ZeroBias Et\")\n",
    "plt.show()\n",
    "\n",
    "print('Mean ZeroBias pT = ' + str(np.mean(ZeroBias.reshape(-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter searching (no quantization here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to train with custom loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "def custom_loss_for_train():\n",
    "    def func(y_true, y_pred):\n",
    "        #MSE(output, input)\n",
    "        loss = K.mean((y_pred - y_true)**2, axis = [1, 2, 3])\n",
    "        \n",
    "        #MSE(output, mean ZB)\n",
    "        #loss = K.mean((y_pred - ZB_mean)**2, axis = [1, 2, 3])\n",
    "        \n",
    "        #MSE(output, 0) for denoising\n",
    "        #loss = K.mean(y_pred**2, axis = [1, 2, 3])\n",
    "        \n",
    "        return loss\n",
    "    return func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypermodel for convolutional autoencoder (usually a teacher model for Knowledge Distillation later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypermodel(hp):\n",
    "    hp_model = tf.keras.Sequential()\n",
    "    hp_model.add(tf.keras.layers.InputLayer(input_shape = (18, 14, 1)))\n",
    "    hp_model.add(layers.Conv2D(filters = hp.Int('filters_1',\n",
    "                                                min_value = 15,\n",
    "                                                max_value = 25,\n",
    "                                                step = 2),\n",
    "                               kernel_size = (3, 3),\n",
    "                               activation = 'relu',\n",
    "                               strides = 1,\n",
    "                               padding = 'same'))\n",
    "    \n",
    "    hp_model.add(layers.AveragePooling2D((2, 2)))\n",
    "    hp_model.add(layers.Conv2D(filters = hp.Int('filters_2',\n",
    "                                                min_value = 15,\n",
    "                                                max_value = 25,\n",
    "                                                step = 2),\n",
    "                               kernel_size = (3, 3),\n",
    "                               activation = 'relu',\n",
    "                               strides = 1,\n",
    "                               padding = 'same'))\n",
    "    \n",
    "    hp_model.add(layers.Conv2D(filters = 1,\n",
    "                               kernel_size = (3, 3),\n",
    "                               activation = 'relu',\n",
    "                               strides = 1,\n",
    "                               padding = 'same'))\n",
    "    \n",
    "    hp_model.add(layers.Conv2D(filters = hp.Int('filters_3',\n",
    "                                                min_value = 15,\n",
    "                                                max_value = 25,\n",
    "                                                step = 2),\n",
    "                               kernel_size = (3, 3),\n",
    "                               activation = 'relu',\n",
    "                               strides = 1,\n",
    "                               padding = 'same'))\n",
    "    \n",
    "    hp_model.add(layers.UpSampling2D((2, 2)))\n",
    "    hp_model.add(layers.Conv2D(filters = hp.Int('filters_4',\n",
    "                                                min_value = 15,\n",
    "                                                max_value = 25,\n",
    "                                                step = 2),\n",
    "                               kernel_size = (3, 3),\n",
    "                               activation = 'relu',\n",
    "                               strides = 1,\n",
    "                               padding = 'same'))\n",
    "    \n",
    "    hp_model.add(layers.Conv2D(filters = 1, kernel_size = (3, 3), activation = 'relu', strides = 1, padding = 'same'))\n",
    "    hp_model.compile(optimizer = 'adam', loss = custom_loss_for_train())\n",
    "    return hp_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypermodel for shallowly dense (usually a student model for Knowledge Distillation later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypermodel(hp):\n",
    "    hp_model = tf.keras.Sequential()\n",
    "    hp_model.add(tf.keras.layers.InputLayer(input_shape = (18, 14, 1)))\n",
    "    hp_model.add(tf.keras.layers.Flatten())\n",
    "    hp_model.add(tf.keras.layers.Dense(units = hp.Int('units_1',\n",
    "                                                      min_value = 10,\n",
    "                                                      max_value = 40,\n",
    "                                                      step = 2),\n",
    "                                       activation = 'relu'))\n",
    "    hp_model.add(tf.keras.layers.Dropout(rate = 0.3))\n",
    "    hp_model.add(tf.keras.layers.Dense(1, activation = 'relu'))\n",
    "    hp_model.compile(optimizer = 'adam', loss = 'mse')\n",
    "    return hp_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set configuration for tuner (Hyperband)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = Hyperband(hypermodel,\n",
    "                 objective = 'val_loss',\n",
    "                 max_epochs = 20,\n",
    "                 factor = 3, #number of models to train in a bracket = 1+log_factor(max_epochs)\n",
    "                 hyperband_iterations = 2, #number of times to iterate over the full Hyperband algorithm\n",
    "                 seed = 10,\n",
    "                 directory = 'hypertuning',\n",
    "                 project_name = 'tune',\n",
    "                 overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition the dataset into train/val/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ZeroBias\n",
    "\n",
    "train_ratio = 0.75\n",
    "val_ratio = 0.2\n",
    "test_ratio = 1 - train_ratio - val_ratio\n",
    "X_train_val, X_test = train_test_split(X, test_size = test_ratio, random_state = 123)\n",
    "X_train, X_val = train_test_split(X_train_val, test_size = val_ratio/(val_ratio + train_ratio), random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the search. Mind the label when training for reconstruction or something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(X_train, X_train,\n",
    "            epochs = 20,\n",
    "            validation_data = (X_val, X_val),\n",
    "            batch_size = 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the best models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary(num_trials = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take one of them for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "model = tuner.hypermodel.build(best_hp)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional autoencoder to be trained for input reconstruction (to be used as a teacher model for Knowledge Distillation later).\n",
    "\n",
    "The encoder part, transforming the (18, 14) region input into a smaller latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ZeroBias[:,:,:,0].reshape(-1,18,14,1)\n",
    "#X = ZeroBias_masked\n",
    "\n",
    "train_ratio = 0.5\n",
    "val_ratio = 0.1\n",
    "test_ratio = 1 - train_ratio - val_ratio\n",
    "X_train_val, X_test = train_test_split(X, test_size = test_ratio, random_state = 123)\n",
    "X_train, X_val = train_test_split(X_train_val, test_size = val_ratio/(val_ratio + train_ratio), random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = tf.keras.Input(shape=(18,14,3), name='input')\n",
    "\n",
    "encoder = layers.Conv2D(30, (3,3), strides=1, padding='same', name='conv2d_1')(encoder_input)\n",
    "encoder = layers.Activation('relu', name='relu_1')(encoder)\n",
    "encoder = layers.AveragePooling2D((2,2), name='pool_1')(encoder)\n",
    "encoder = layers.Conv2D(40, (3,3), strides=1, padding='same', name='conv2d_2')(encoder)\n",
    "encoder = layers.Activation('relu', name='relu_2')(encoder)\n",
    "encoder = layers.Flatten(name='flatten')(encoder)\n",
    "\n",
    "encoder_output = layers.Dense(120, activation='relu', name='latent')(encoder)\n",
    "\n",
    "encoder = tf.keras.models.Model(encoder_input, encoder_output)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoder part, reconstructing from latent space back to the (18, 14) region input. Note the Conv2DTranspose is not yet supported in hls4ml, but ok to use if it is going to be distilled to another network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = layers.Dense(9*7*40, name='dense')(encoder_output)\n",
    "decoder = layers.Reshape((9,7,40), name='reshape')(decoder)\n",
    "decoder = layers.Activation('relu', name='relu_3')(decoder)\n",
    "decoder = layers.Conv2D(40, (3,3), strides=1, padding='same', name='conv2d_3')(decoder)\n",
    "decoder = layers.Activation('relu', name='relu_4')(decoder)\n",
    "decoder = layers.UpSampling2D((2,2), name='upsampling')(decoder)\n",
    "decoder = layers.Conv2D(30, (3,3), strides=1, padding='same', name='conv2d_4')(decoder)\n",
    "decoder = layers.Activation('relu', name='relu_5')(decoder)\n",
    "\n",
    "decoder_output = layers.Conv2D(3, (3,3), activation='relu', strides=1, padding='same', name='output')(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(encoder_input, decoder_output)\n",
    "model.summary()\n",
    "#keras.utils.plot_model(encoder, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@@@@@@@@@@@@@@@@@@@@ bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ZeroBias\n",
    "\n",
    "train_ratio = 0.75\n",
    "val_ratio = 0.2\n",
    "test_ratio = 1 - train_ratio - val_ratio\n",
    "X_train_val, X_test = train_test_split(X, test_size = test_ratio, random_state = 123)\n",
    "X_train, X_val = train_test_split(X_train_val, test_size = val_ratio/(val_ratio + train_ratio), random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "encoder_input = tf.keras.Input(shape=(18,14,1), name='Et_input')\n",
    "encoder_Et = layers.Conv2D(20, (3,3), strides=1, padding='same', name='Et_conv2d_1')(encoder_input)\n",
    "encoder_Et = layers.Activation('relu', name='Et_relu_1')(encoder_Et)\n",
    "encoder_Et = layers.AveragePooling2D((2,2), name='Et_pooling')(encoder_Et)\n",
    "encoder_Et = layers.Conv2D(30, (3,3), strides=1, padding='same', name='Et_conv2d_2')(encoder_Et)\n",
    "encoder_Et = layers.Activation('relu', name='Et_relu_2')(encoder_Et)\n",
    "encoder_Et = layers.Flatten(name='Et_flatten')(encoder_Et)\n",
    "encoder_Et = layers.Dense(100, name='Et_dense')(encoder_Et)\n",
    "encoder_Et = layers.Activation('relu', name='Et_relu_3')(encoder_Et)\n",
    "encoder_Et = tf.keras.models.Model(encoder_input, encoder_Et)\n",
    "\n",
    "encoder_input = tf.keras.Input(shape=(18,14,1), name='EG_input')\n",
    "encoder_EG = layers.Conv2D(20, (3,3), strides=1, padding='same', name='EG_conv2d_1')(encoder_input)\n",
    "encoder_EG = layers.Activation('relu', name='EG_relu_1')(encoder_EG)\n",
    "encoder_EG = layers.AveragePooling2D((2,2), name='EG_pooling')(encoder_EG)\n",
    "encoder_EG = layers.Conv2D(30, (3,3), strides=1, padding='same', name='EG_conv2d_2')(encoder_EG)\n",
    "encoder_EG = layers.Activation('relu', name='EG_relu_2')(encoder_EG)\n",
    "encoder_EG = layers.Flatten(name='EG_flatten')(encoder_EG)\n",
    "encoder_EG = layers.Dense(100, name='EG_dense')(encoder_EG)\n",
    "encoder_EG = layers.Activation('relu', name='EG_relu_3')(encoder_EG)\n",
    "encoder_EG = tf.keras.models.Model(encoder_input, encoder_EG)\n",
    "\n",
    "encoder_input = tf.keras.Input(shape=(18,14,1), name='Tau_input')\n",
    "encoder_Tau = layers.Conv2D(20, (3,3), strides=1, padding='same', name='Tau_conv2d_1')(encoder_input)\n",
    "encoder_Tau = layers.Activation('relu', name='Tau_relu_1')(encoder_Tau)\n",
    "encoder_Tau = layers.AveragePooling2D((2,2), name='Tau_pooling')(encoder_Tau)\n",
    "encoder_Tau = layers.Conv2D(30, (3,3), strides=1, padding='same', name='Tau_conv2d_2')(encoder_Tau)\n",
    "encoder_Tau = layers.Activation('relu', name='Tau_relu_2')(encoder_Tau)\n",
    "encoder_Tau = layers.Flatten(name='Tau_flatten')(encoder_Tau)\n",
    "encoder_Tau = layers.Dense(100, name='Tau_dense')(encoder_Tau)\n",
    "encoder_Tau = layers.Activation('relu', name='Tau_relu_3')(encoder_Tau)\n",
    "encoder_Tau = tf.keras.models.Model(encoder_input, encoder_Tau)\n",
    "\n",
    "encoder_output = layers.concatenate([encoder_Et.output, encoder_EG.output, encoder_Tau.output], name='latent_combine')\n",
    "encoder_output = layers.Dense(100, name='latent_dense')(encoder_output)\n",
    "encoder_output = layers.Activation('relu', name='latent_relu')(encoder_output)\n",
    "\n",
    "encoder = tf.keras.models.Model([encoder_Et.input, encoder_EG.input, encoder_Tau.input], encoder_output)\n",
    "encoder.summary()\n",
    "#keras.utils.plot_model(encoder, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = layers.Dense(9*7*20, name='decoder_dense')(encoder_output)\n",
    "decoder = layers.Reshape((9,7,20), name='decoder_reshape')(decoder)\n",
    "decoder = layers.Activation('relu', name='decoder_relu_1')(decoder)\n",
    "decoder = layers.Conv2D(30, (3,3), strides=1, padding='same', name='decoder_conv2d_1')(decoder)\n",
    "decoder = layers.Activation('relu', name='decoder_relu_2')(decoder)\n",
    "decoder = layers.UpSampling2D((2,2), name='decoder_upsampling')(decoder)\n",
    "decoder = layers.Conv2D(20, (3,3), strides=1, padding='same', name='decoder_conv2d_2')(decoder)\n",
    "decoder = layers.Activation('relu', name='decoder_relu_3')(decoder)\n",
    "decoder = layers.Conv2D(3, (3,3), strides=1, padding='same', name='decoder_conv2d_3')(decoder)\n",
    "decoder = layers.Activation('relu', name='decoder_relu_4')(decoder)\n",
    "\n",
    "#decoder = tf.keras.models.Model(encoder_output, decoder)\n",
    "#decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_Et = layers.Dense(9*7*20, name='decoder_Et_dense')(encoder_output)\n",
    "decoder_Et = layers.Reshape((9,7,20), name='decoder_Et_reshape')(decoder_Et)\n",
    "decoder_Et = layers.Activation('relu', name='decoder_Et_relu_1')(decoder_Et)\n",
    "decoder_Et = layers.Conv2D(30, (3,3), strides=1, padding='same', name='decoder_Et_conv2d_1')(decoder_Et)\n",
    "decoder_Et = layers.Activation('relu', name='decoder_Et_relu_2')(decoder_Et)\n",
    "decoder_Et = layers.UpSampling2D((2,2), name='decoder_Et_upsampling')(decoder_Et)\n",
    "decoder_Et = layers.Conv2D(20, (3,3), strides=1, padding='same', name='decoder_Et_conv2d_2')(decoder_Et)\n",
    "decoder_Et = layers.Activation('relu', name='decoder_Et_relu_3')(decoder_Et)\n",
    "decoder_Et = layers.Conv2D(1, (3,3), strides=1, padding='same', name='decoder_Et_conv2d_3')(decoder_Et)\n",
    "decoder_Et = layers.Activation('relu', name='decoder_Et_relu_4')(decoder_Et)\n",
    "#decoder_Et = tf.keras.models.Model(encoder_output, decoder_Et)\n",
    "\n",
    "decoder_EG = layers.Dense(9*7*20, name='decoder_EG_dense')(encoder_output)\n",
    "decoder_EG = layers.Reshape((9,7,20), name='decoder_EG_reshape')(decoder_EG)\n",
    "decoder_EG = layers.Activation('relu', name='decoder_EG_relu_1')(decoder_EG)\n",
    "decoder_EG = layers.Conv2D(30, (3,3), strides=1, padding='same', name='decoder_EG_conv2d_1')(decoder_EG)\n",
    "decoder_EG = layers.Activation('relu', name='decoder_EG_relu_2')(decoder_EG)\n",
    "decoder_EG = layers.UpSampling2D((2,2), name='decoder_EG_upsampling')(decoder_EG)\n",
    "decoder_EG = layers.Conv2D(20, (3,3), strides=1, padding='same', name='decoder_EG_conv2d_2')(decoder_EG)\n",
    "decoder_EG = layers.Activation('relu', name='decoder_EG_relu_3')(decoder_EG)\n",
    "decoder_EG = layers.Conv2D(1, (3,3), strides=1, padding='same', name='decoder_EG_conv2d_3')(decoder_EG)\n",
    "decoder_EG = layers.Activation('relu', name='decoder_EG_relu_4')(decoder_EG)\n",
    "#decoder_EG = tf.keras.models.Model(encoder_output, decoder_EG)\n",
    "\n",
    "decoder_Tau = layers.Dense(9*7*20, name='decoder_Tau_dense')(encoder_output)\n",
    "decoder_Tau = layers.Reshape((9,7,20), name='decoder_Tau_reshape')(decoder_Tau)\n",
    "decoder_Tau = layers.Activation('relu', name='decoder_Tau_relu_1')(decoder_Tau)\n",
    "decoder_Tau = layers.Conv2D(30, (3,3), strides=1, padding='same', name='decoder_Tau_conv2d_1')(decoder_Tau)\n",
    "decoder_Tau = layers.Activation('relu', name='decoder_Tau_relu_2')(decoder_Tau)\n",
    "decoder_Tau = layers.UpSampling2D((2,2), name='decoder_Tau_upsampling')(decoder_Tau)\n",
    "decoder_Tau = layers.Conv2D(20, (3,3), strides=1, padding='same', name='decoder_Tau_conv2d_2')(decoder_Tau)\n",
    "decoder_Tau = layers.Activation('relu', name='decoder_Tau_relu_3')(decoder_Tau)\n",
    "decoder_Tau = layers.Conv2D(1, (3,3), strides=1, padding='same', name='decoder_Tau_conv2d_3')(decoder_Tau)\n",
    "decoder_Tau = layers.Activation('relu', name='decoder_Tau_relu_4')(decoder_Tau)\n",
    "#decoder_Tau = tf.keras.models.Model(encoder_output, decoder_Tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Model([encoder_Et.input, encoder_EG.input, encoder_Tau.input], [decoder_Et,decoder_EG,decoder_Tau])\n",
    "model.summary()\n",
    "keras.utils.plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 20\n",
    "encoder_inputs = tf.keras.Input(shape = (18, 14, 1))\n",
    "\n",
    "encoding = layers.Conv2D(20, (3, 3), strides = 1, padding = 'same')(encoder_inputs)\n",
    "encoding = layers.Activation('relu')(encoding)\n",
    "encoding = layers.AveragePooling2D((2, 2))(encoding)\n",
    "encoding = layers.Conv2D(20, (3, 3), strides = 1, padding = 'same')(encoding)\n",
    "encoding = layers.Activation('relu')(encoding)\n",
    "encoding = layers.Flatten()(encoding)\n",
    "\n",
    "z_mean = layers.Dense(latent_dim, name = 'z_mean')(encoding)\n",
    "z_log_var = layers.Dense(latent_dim, name = 'z_log_var')(encoding)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "encoder = tf.keras.Model(encoder_inputs, [z_mean, z_log_var, z], name = 'encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_inputs = tf.keras.Input(shape = (latent_dim,))\n",
    "\n",
    "decoding = layers.Dense(9 * 7 * 20)(latent_inputs)\n",
    "decoding = layers.Reshape((9, 7, 20))(decoding)\n",
    "decoding = layers.Activation('relu')(decoding)\n",
    "decoding = layers.Conv2D(20, (3, 3), strides = 1, padding = 'same')(decoding)\n",
    "decoding = layers.Activation('relu')(decoding)\n",
    "decoding = layers.UpSampling2D((2, 2))(decoding)\n",
    "decoding = layers.Conv2D(20, (3, 3), strides = 1, padding = 'same')(decoding)\n",
    "decoding = layers.Activation('relu')(decoding)\n",
    "\n",
    "decoder_outputs = layers.Conv2D(1, (3, 3), activation = 'sigmoid', strides = 1, padding = 'same')(decoding)\n",
    "\n",
    "decoder = tf.keras.Model(latent_inputs, decoder_outputs, name = 'decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = 10*tf.reduce_mean(tf.reduce_sum(keras.losses.binary_crossentropy(data, reconstruction), axis = (1, 2)))\n",
    "            #reconstruction_loss = 100*tf.reduce_mean(tf.square(data - reconstruction), axis = (1, 2, 3))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(-0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)), axis = 1))\n",
    "            #total_loss = reconstruction_loss + kl_loss\n",
    "            #total_loss = reconstruction_loss\n",
    "            total_loss = kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "et_scale = 1\n",
    "history = vae.fit(X_train/et_scale, epochs = 8,\n",
    "                  #validation_data = (X_val/et_scale,X_val/et_scale),\n",
    "                  batch_size = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "axes_left = plt.subplot(2, 2, 1)\n",
    "axes_left.plot(history.history['loss'], label = 'Total loss = Reco + KL', c = 'g', linestyle = 'solid')\n",
    "axes_left.plot(history.history['reconstruction_loss'], label = 'Reconstruction loss (BCE)', c = 'g' , linestyle = 'dashed')\n",
    "axes_left.legend(loc = \"upper left\")\n",
    "axes_left.set_xlabel('Epoch')\n",
    "axes_left.set_ylabel('Total loss', c = 'g')\n",
    "\n",
    "axes_right = axes_left.twinx()\n",
    "axes_right.plot(history.history['kl_loss'], label = 'KL loss', c = 'r', linestyle = 'dashed')\n",
    "axes_right.legend(loc = \"upper right\")\n",
    "axes_right.set_ylabel('KL loss', c = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['kl_loss'], label = 'KL loss', c = 'r', linestyle = 'dashed')\n",
    "axes.legend(loc = \"upper left\")\n",
    "axes.set_yscale(value = \"log\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('KL loss', c = 'g')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_mu, X_test_logvar, X_test_z = vae.encoder.predict(X_test/et_scale)\n",
    "X_test_predict = vae.decoder.predict(X_test_z)\n",
    "\n",
    "MC_zb_mu = []\n",
    "MC_zb_logvar = []\n",
    "MC_zb_z = []\n",
    "MC_zb_predict = []\n",
    "for i in range(len(MC_zb)):\n",
    "    mu, logvar, z = vae.encoder.predict(MC_zb[i]/et_scale)\n",
    "    predict = vae.decoder.predict(z)\n",
    "    MC_zb_mu.append(mu)\n",
    "    MC_zb_logvar.append(logvar)\n",
    "    MC_zb_z.append(z)\n",
    "    MC_zb_predict.append(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 1\n",
    "n = 5\n",
    "\n",
    "df_z_mu_sig = pd.DataFrame(MC_zb_mu[n][1:9000, i], columns = [\"z_mu[{}]\".format(i)])\n",
    "df_z_mu_sig[\"z_mu[{}]\".format(j)] = MC_zb_mu[n][1:9000, j]\n",
    "df_z_mu_sig[\"dataset\"] = MC_files[n]\n",
    "df_z_mu_zb = pd.DataFrame(X_test_mu[1:9000, i], columns = [\"z_mu[{}]\".format(i)])\n",
    "df_z_mu_zb[\"z_mu[{}]\".format(j)] = X_test_mu[1:9000, j]\n",
    "df_z_mu_zb[\"dataset\"] = \"test (ZB)\"\n",
    "df_z_mu = pd.concat([df_z_mu_sig,df_z_mu_zb])\n",
    "\n",
    "df_z_sigma_sig = pd.DataFrame(np.exp(MC_zb_logvar[n][1:9000, i]/2), columns = [\"z_sigma[{}]\".format(i)])\n",
    "df_z_sigma_sig[\"z_sigma[{}]\".format(j)] = np.exp(MC_zb_logvar[n][1:9000, j]/2)\n",
    "df_z_sigma_sig[\"dataset\"] = MC_files[n]\n",
    "df_z_sigma_zb = pd.DataFrame(np.exp(X_test_logvar[1:9000, i]/2), columns = [\"z_sigma[{}]\".format(i)])\n",
    "df_z_sigma_zb[\"z_sigma[{}]\".format(j)] = np.exp(X_test_logvar[1:9000, j]/2)\n",
    "df_z_sigma_zb[\"dataset\"] = \"test (ZB)\"\n",
    "df_z_sigma = pd.concat([df_z_sigma_sig,df_z_sigma_zb])\n",
    "\n",
    "df_z_sig = pd.DataFrame(np.exp(MC_zb_z[n][1:9000, i]/2), columns = [\"z[{}]\".format(i)])\n",
    "df_z_sig[\"z[{}]\".format(j)] = np.exp(MC_zb_z[n][1:9000, j]/2)\n",
    "df_z_sig[\"dataset\"] = MC_files[n]\n",
    "df_z_zb = pd.DataFrame(np.exp(X_test_z[1:9000, i]/2), columns = [\"z[{}]\".format(i)])\n",
    "df_z_zb[\"z[{}]\".format(j)] = np.exp(X_test_z[1:9000, j]/2)\n",
    "df_z_zb[\"dataset\"] = \"test (ZB)\"\n",
    "df_z = pd.concat([df_z_sig,df_z_zb])\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.jointplot(x = df_z_mu[\"z_mu[{}]\".format(i)], y = df_z_mu[\"z_mu[{}]\".format(j)], hue = df_z_mu[\"dataset\"], height = 8, ratio = 5,\n",
    "              #xlim = (-0.001, 0.001), ylim = (-0.001, 0.001),\n",
    "              marker = '.', alpha = 1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.jointplot(x = df_z_sigma[\"z_sigma[{}]\".format(i)], y = df_z_sigma[\"z_sigma[{}]\".format(j)], hue = df_z_sigma[\"dataset\"], height = 8, ratio = 5,\n",
    "              #xlim = (-8, 8), ylim = (-8, 8),\n",
    "              marker = '.', alpha = 1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.jointplot(x = df_z[\"z[{}]\".format(i)], y = df_z[\"z[{}]\".format(j)], hue = df_z[\"dataset\"], height = 8, ratio = 5,\n",
    "              #xlim = (-8, 8), ylim = (-8, 8),\n",
    "              marker = '.', alpha = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_for_pred(y_true, y_pred, choice):\n",
    "    #MSE\n",
    "    if choice == 0:\n",
    "        loss = np.mean((y_true - y_pred)**2, axis = (1, 2, 3))\n",
    "        return loss\n",
    "    \n",
    "    #MSE for de-noising model\n",
    "    if choice == 1:\n",
    "        loss = np.mean(y_pred**2, axis = (1, 2, 3))\n",
    "        return loss\n",
    "    \n",
    "    #VAE radius loss\n",
    "    if choice == 2:\n",
    "        loss = np.sqrt(np.sum(y_pred**2, axis = 1))\n",
    "        return loss\n",
    "    \n",
    "    #VAE KL loss\n",
    "    if choice == 3:\n",
    "        loss = -0.5 * np.sum(1.0 + y_pred - y_true**2 - np.exp(y_pred), axis = 1)\n",
    "        return loss\n",
    "    \n",
    "    #BCE loss\n",
    "    if choice == 4:\n",
    "        #loss = np.mean(np.sum(keras.losses.binary_crossentropy(y_true, y_pred), axis = (1, 2)))\n",
    "        loss = np.sum(keras.losses.binary_crossentropy(y_true, y_pred), axis = (1, 2))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For VAE\n",
    "X_test_vaeloss_mse = custom_loss_for_pred(X_test/et_scale, X_test_predict, 0)\n",
    "MC_zb_vaeloss_mse = []\n",
    "for i in range(len(MC_zb)):\n",
    "    MC_zb_vaeloss_mse.append(custom_loss_for_pred(MC_zb[i]/et_scale, MC_zb_predict[i], 0))\n",
    "    \n",
    "X_test_vaeloss_bce = custom_loss_for_pred(X_test/et_scale, X_test_predict, 4)\n",
    "MC_zb_vaeloss_bce = []\n",
    "for i in range(len(MC_zb)):\n",
    "    MC_zb_vaeloss_bce.append(custom_loss_for_pred(MC_zb[i]/et_scale, MC_zb_predict[i], 4))\n",
    "\n",
    "X_test_vaeloss_radius = custom_loss_for_pred(X_test, X_test_mu, 2)\n",
    "MC_zb_vaeloss_radius = []\n",
    "for i in range(len(MC_zb)):\n",
    "    MC_zb_vaeloss_radius.append(custom_loss_for_pred(MC_zb[i], MC_zb_mu[i], 2))\n",
    "    \n",
    "X_test_vaeloss_kl = custom_loss_for_pred(X_test_mu, X_test_logvar, 3)\n",
    "MC_zb_vaeloss_kl = []\n",
    "for i in range(len(MC_zb)):\n",
    "    MC_zb_vaeloss_kl.append(custom_loss_for_pred(MC_zb_mu[i], MC_zb_logvar[i], 3))\n",
    "\n",
    "weight_mse = 0\n",
    "weight_bce = 0\n",
    "weight_radius = 0\n",
    "weight_kl = 1.0\n",
    "\n",
    "X_test_vaeloss = weight_mse*X_test_vaeloss_mse + weight_bce*X_test_vaeloss_bce + weight_radius*X_test_vaeloss_radius + weight_kl*X_test_vaeloss_kl\n",
    "MC_zb_vaeloss = []\n",
    "for i in range(len(MC_zb)):\n",
    "    MC_zb_vaeloss.append(weight_mse*MC_zb_vaeloss_mse[i] + weight_bce*MC_zb_vaeloss_bce[i] + weight_radius*MC_zb_vaeloss_radius[i] + weight_kl*MC_zb_vaeloss_kl[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Original vs Reconstructed\n",
    "#show_ZB = True\n",
    "show_ZB = False\n",
    "n = 5\n",
    "for i in range(580,590):\n",
    "    fig, ax = plt.subplots(figsize = (17,17))\n",
    "    if show_ZB == True:\n",
    "        print('ZB test\\nloss = ' + str(X_test_vaeloss[i]))\n",
    "    else:\n",
    "        print(str(MC_files[n]) + '\\nloss = ' + str(MC_zb_vaeloss[n][i]))\n",
    "    ax = plt.subplot(3, 3, 1)\n",
    "    if show_ZB == True:\n",
    "        ax = sns.heatmap(X_test[i,:,:,0].reshape(18, 14)/et_scale, vmin = 0, vmax = X_test[i,:,:,0].max()/et_scale, cmap = \"Blues\", cbar_kws = {'label': 'Scaled ET'})\n",
    "    else:\n",
    "        ax = sns.heatmap(MC_zb[n][i,:,:,0].reshape(18, 14)/et_scale, vmin = 0, vmax = MC_zb[n][i,:,:,0].max()/et_scale, cmap = \"Blues\", cbar_kws = {'label': 'Scaled ET'})\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title('Original')\n",
    "    \n",
    "    ax = plt.subplot(3, 3, 2)\n",
    "    if show_ZB == True:\n",
    "        ax = sns.heatmap(X_test_predict[i,:,:,0].reshape(18, 14), vmin = 0, vmax = X_test[i,:,:,0].max()/et_scale, cmap = \"Blues\", cbar_kws = {'label': 'Scaled ET'})\n",
    "    else:\n",
    "        ax = sns.heatmap(MC_zb_predict[n][i,:,:,0].reshape(18, 14), vmin = 0, vmax = MC_zb[n][i,:,:,0].max()/et_scale, cmap = \"Blues\", cbar_kws = {'label': 'Scaled ET'})\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title('Reconstructed')\n",
    "    \n",
    "    ax = plt.subplot(3, 3, 3)\n",
    "    if show_ZB == True:\n",
    "        ax = sns.heatmap(np.absolute(X_test_predict[i,:,:,0] - X_test[i,:,:,0]/et_scale).reshape(18, 14), vmin = 0, vmax = X_test[i,:,:,0].max()/et_scale, cmap = \"Blues\", cbar_kws = {'label': 'Scaled ET'})\n",
    "    else:\n",
    "        ax = sns.heatmap(np.absolute(MC_zb_predict[n][i,:,:,0] - MC_zb[n][i,:,:,0]/et_scale).reshape(18, 14), vmin = 0, vmax = MC_zb[n][i,:,:,0].max()/et_scale, cmap = \"Blues\", cbar_kws = {'label': 'Scaled ET'})\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title('abs(original-reconstructed)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nbins = 20\n",
    "rmin = 0\n",
    "rmax = 1000\n",
    "plt.hist(X_test_vaeloss_mse, density = 1, bins = nbins, alpha = 0.3, label = 'test (ZeroBias)', range = (rmin, rmax), log = True)\n",
    "plt.hist(MC_zb_vaeloss_mse[0], density = 1, bins = nbins, label = 'QCD', alpha = 0.1, histtype = 'stepfilled', range = (rmin, rmax))\n",
    "for i in range(3,7):\n",
    "    plt.hist(MC_zb_vaeloss_mse[i], density = 1, bins = nbins, label = MC_files[i], histtype = 'step', range = (rmin, rmax))\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel(\"Reconstruction MSE loss\")\n",
    "plt.show()\n",
    "\n",
    "nbins = 20\n",
    "rmin = 0\n",
    "rmax = 1000\n",
    "plt.hist(X_test_vaeloss_bce, density = 1, bins = nbins, alpha = 0.3, label = 'test (ZeroBias)', range = (rmin, rmax), log = True)\n",
    "plt.hist(MC_zb_vaeloss_bce[0], density = 1, bins = nbins, label = 'QCD', alpha = 0.1, histtype = 'stepfilled', range = (rmin, rmax))\n",
    "for i in range(3,7):\n",
    "    plt.hist(MC_zb_vaeloss_bce[i], density = 1, bins = nbins, label = MC_files[i], histtype = 'step', range = (rmin, rmax))\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel(\"Reconstruction BCE loss\")\n",
    "plt.show()\n",
    "\n",
    "nbins = 40\n",
    "rmin = 0\n",
    "rmax = 0.0001\n",
    "plt.hist(X_test_vaeloss_radius, density = 1, bins = nbins, alpha = 0.3, label = 'test (ZeroBias)', range = (rmin, rmax), log = True)\n",
    "plt.hist(MC_zb_vaeloss_radius[0], density = 1, bins = nbins, label = 'QCD', alpha = 0.1, histtype = 'stepfilled', range = (rmin, rmax))\n",
    "for i in range(3,7):\n",
    "    plt.hist(MC_zb_vaeloss_radius[i], density = 1, bins = nbins, label = MC_files[i], histtype = 'step', range = (rmin, rmax))\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel(\"Radius loss\")\n",
    "plt.show()\n",
    "\n",
    "nbins = 40\n",
    "rmin = 0\n",
    "rmax = 0.00001\n",
    "plt.hist(X_test_vaeloss_kl, density = 1, bins = nbins, alpha = 0.3, label = 'test (ZeroBias)', range = (rmin, rmax), log = True)\n",
    "plt.hist(MC_zb_vaeloss_kl[0], density = 1, bins = nbins, label = 'QCD', alpha = 0.1, histtype = 'stepfilled', range = (rmin, rmax))\n",
    "for i in range(3,7):\n",
    "    plt.hist(MC_zb_vaeloss_kl[i], density = 1, bins = nbins, label = MC_files[i], histtype = 'step', range = (rmin, rmax))\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel(\"KL loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 5\n",
    "\n",
    "df_vaeloss_sig = pd.DataFrame(MC_zb_vaeloss_mse[n][1:9000], columns = [\"MSE loss\"])\n",
    "df_vaeloss_sig[\"BCE loss\"] = MC_zb_vaeloss_bce[n][1:9000]\n",
    "df_vaeloss_sig[\"Radius loss\"] = MC_zb_vaeloss_radius[n][1:9000]\n",
    "df_vaeloss_sig[\"KL loss\"] = MC_zb_vaeloss_kl[n][1:9000]\n",
    "df_vaeloss_sig[\"dataset\"] = MC_files[n]\n",
    "df_vaeloss_zb = pd.DataFrame(X_test_vaeloss_mse[1:9000], columns = [\"MSE loss\"])\n",
    "df_vaeloss_zb[\"BCE loss\"] = X_test_vaeloss_bce[1:9000]\n",
    "df_vaeloss_zb[\"Radius loss\"] = X_test_vaeloss_radius[1:9000]\n",
    "df_vaeloss_zb[\"KL loss\"] = X_test_vaeloss_kl[1:9000]\n",
    "df_vaeloss_zb[\"dataset\"] = \"test (ZB)\"\n",
    "\n",
    "df_vaeloss = pd.concat([df_vaeloss_sig,df_vaeloss_zb])\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.jointplot(x = df_vaeloss[\"MSE loss\"], y = df_vaeloss[\"BCE loss\"], height = 8, ratio = 5, hue = df_vaeloss[\"dataset\"],\n",
    "              xlim = (0.0, 0.05), ylim = (0, 100),\n",
    "              marker = '.', alpha = 1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.jointplot(x = df_vaeloss[\"Radius loss\"], y = df_vaeloss[\"KL loss\"], height = 8, ratio = 5, hue = df_vaeloss[\"dataset\"],\n",
    "              xlim = (0, 10), ylim = (0, 50),\n",
    "              marker = '.', alpha = 1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.jointplot(x = df_vaeloss[\"MSE loss\"], y = df_vaeloss[\"KL loss\"], height = 8, ratio = 5, hue = df_vaeloss[\"dataset\"],\n",
    "              xlim = (0, 0.05), ylim = (0, 50),\n",
    "              marker = '.', alpha = 1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.jointplot(x = df_vaeloss[\"BCE loss\"], y = df_vaeloss[\"KL loss\"], height = 8, ratio = 5 ,hue = df_vaeloss[\"dataset\"],\n",
    "              xlim = (0, 100), ylim = (0, 40),\n",
    "              marker = '.', alpha = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZeroBias_mean = np.mean(ZeroBias, axis = 0)\n",
    "\n",
    "baseline_zb = np.mean((X_test - ZeroBias_mean)**2, axis = (1, 2))\n",
    "baseline_mc = []\n",
    "for i in range(len(MC_zb)):\n",
    "    baseline_mc.append(np.mean((MC_zb[i] - ZeroBias_mean)**2, axis = (1, 2)))\n",
    "\n",
    "Y_zb = np.zeros((X_test.shape[0], 1))\n",
    "Y_mc = []\n",
    "for i in range(len(MC)):\n",
    "    Y_mc.append(np.ones((MC_zb[i].shape[0], 1)))\n",
    "\n",
    "Y_true = []\n",
    "Y_baseline = []\n",
    "Y_mse = []\n",
    "Y_bce = []\n",
    "Y_radius = []\n",
    "Y_kl = []\n",
    "Y_total = []\n",
    "for i in range(len(MC)):\n",
    "    Y_true.append(np.concatenate((Y_mc[i], Y_zb)))\n",
    "    Y_baseline.append(np.concatenate((baseline_mc[i], baseline_zb)))\n",
    "    Y_mse.append(np.concatenate((MC_zb_vaeloss_mse[i], X_test_vaeloss_mse)))\n",
    "    Y_bce.append(np.concatenate((MC_zb_vaeloss_bce[i], X_test_vaeloss_bce)))\n",
    "    Y_radius.append(np.concatenate((MC_zb_vaeloss_radius[i], X_test_vaeloss_radius)))\n",
    "    Y_kl.append(np.concatenate((MC_zb_vaeloss_kl[i], X_test_vaeloss_kl)))\n",
    "    Y_total.append(np.concatenate((MC_zb_vaeloss[i], X_test_vaeloss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "\n",
    "plt.figure(figsize = (13, 13))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "\n",
    "fpr_baseline = np.empty((Y_true[n].shape[0],1))\n",
    "tpr_baseline = np.empty((Y_true[n].shape[0],1))\n",
    "thresholds_baseline = np.empty((Y_true[n].shape[0],1))\n",
    "roc_auc_baseline = np.empty((Y_true[n].shape[0],1))\n",
    "\n",
    "fpr_mse = np.empty((Y_true[n].shape[0],1))\n",
    "tpr_mse = np.empty((Y_true[n].shape[0],1))\n",
    "thresholds_mse = np.empty((Y_true[n].shape[0],1))\n",
    "roc_auc_mse = np.empty((Y_true[n].shape[0],1))\n",
    "\n",
    "fpr_bce = np.empty((Y_true[n].shape[0],1))\n",
    "tpr_bce = np.empty((Y_true[n].shape[0],1))\n",
    "thresholds_bce = np.empty((Y_true[n].shape[0],1))\n",
    "roc_auc_bce = np.empty((Y_true[n].shape[0],1))\n",
    "\n",
    "fpr_radius = np.empty((Y_true[n].shape[0],1))\n",
    "tpr_radius = np.empty((Y_true[n].shape[0],1))\n",
    "thresholds_radius = np.empty((Y_true[n].shape[0],1))\n",
    "roc_auc_radius = np.empty((Y_true[n].shape[0],1))\n",
    "\n",
    "fpr_kl = np.empty((Y_true[n].shape[0],1))\n",
    "tpr_kl = np.empty((Y_true[n].shape[0],1))\n",
    "thresholds_kl = np.empty((Y_true[n].shape[0],1))\n",
    "roc_auc_kl = np.empty((Y_true[n].shape[0],1))\n",
    "\n",
    "fpr_total = np.empty((Y_true[n].shape[0],1))\n",
    "tpr_total = np.empty((Y_true[n].shape[0],1))\n",
    "thresholds_total = np.empty((Y_true[n].shape[0],1))\n",
    "roc_auc_total = np.empty((Y_true[n].shape[0],1))\n",
    "\n",
    "fpr_baseline, tpr_baseline, thresholds_baseline = roc_curve(Y_true[n], Y_baseline[n])\n",
    "roc_auc_baseline = auc(fpr_baseline, tpr_baseline)\n",
    "\n",
    "fpr_mse, tpr_mse, thresholds_mse = roc_curve(Y_true[n], Y_mse[n])\n",
    "roc_auc_mse = auc(fpr_mse, tpr_mse)\n",
    "\n",
    "fpr_bce, tpr_bce, thresholds_bce = roc_curve(Y_true[n], Y_bce[n])\n",
    "roc_auc_bce = auc(fpr_bce, tpr_bce)\n",
    "\n",
    "fpr_radius, tpr_radius, thresholds_radius = roc_curve(Y_true[n], Y_radius[n])\n",
    "roc_auc_radius = auc(fpr_radius, tpr_radius)\n",
    "\n",
    "fpr_kl, tpr_kl, thresholds_kl = roc_curve(Y_true[n], Y_kl[n])\n",
    "roc_auc_kl = auc(fpr_kl, tpr_kl)\n",
    "\n",
    "fpr_total, tpr_total, thresholds_total = roc_curve(Y_true[n], Y_total[n])\n",
    "roc_auc_total = auc(fpr_total, tpr_total)\n",
    "\n",
    "lw = 2\n",
    "\n",
    "axes.plot(fpr_baseline, tpr_baseline, linestyle = '--', lw = lw, color = 'red', label = 'Cut-flow baseline (AUC = %.4f)' % (roc_auc_baseline))\n",
    "axes.plot(fpr_mse, tpr_mse, linestyle = '-', lw = lw, label = 'VAE anomaly score = MSE loss (AUC = %.4f)' % (roc_auc_mse))\n",
    "axes.plot(fpr_bce, tpr_bce, linestyle = '-', lw = lw, label = 'VAE anomaly score = BCE loss (AUC = %.4f)' % (roc_auc_bce))\n",
    "axes.plot(fpr_radius, tpr_radius, linestyle = '-', lw = lw, label = 'VAE anomaly score = radius loss (AUC = %.4f)' % (roc_auc_radius))\n",
    "axes.plot(fpr_kl, tpr_kl, linestyle = '-', lw = lw, label = 'VAE anomaly score = KL loss (AUC = %.4f)' % (roc_auc_kl))\n",
    "axes.plot(fpr_total, tpr_total, linestyle = '--', lw = lw, label = 'VAE anomaly score = BCE + KL (AUC = %.4f)' % (roc_auc_total))\n",
    "\n",
    "axes.plot([0.002, 0.002], [0, 1], linestyle = '--', lw = 1, color = 'black', label = 'FPR = 0.2% ~ (100 kHz)/(ZB rate)')\n",
    "axes.set_xlim([0.00001, 1.0])\n",
    "#axes.set_xlim([0, 1.0])\n",
    "axes.set_ylim([0, 1.0])\n",
    "#axes.set_ylim([0.9, 1.0])\n",
    "axes.set_xscale(value = \"log\")\n",
    "#axes.set_yscale(value = \"log\")\n",
    "axes.set_xlabel('False Positive Rate (FPR)')\n",
    "axes.set_ylabel('True Positive Rate (TPR)')\n",
    "axes.set_title(MC_files[n] + ' vs ZB')\n",
    "axes.legend(loc='center left', bbox_to_anchor = (0.6, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition the dataset into train/val/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ZeroBias\n",
    "\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.10\n",
    "test_ratio = 1 - train_ratio - val_ratio\n",
    "X_train_val, X_test = train_test_split(X, test_size = test_ratio, random_state = 1234)\n",
    "X_train, X_val = train_test_split(X_train_val, test_size = val_ratio/(val_ratio + train_ratio), random_state = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training. Mind the label when training for reconstruction or something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, X_train,\n",
    "                    epochs = 60,\n",
    "                    validation_data = (X_val, X_val),\n",
    "                    batch_size = 1024,\n",
    "                    callbacks = [\n",
    "                        tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 10, mode = \"min\")\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit([np.delete(X_train,[1,2],axis=3),\n",
    "                     np.delete(X_train,[0,2],axis=3),\n",
    "                     np.delete(X_train,[0,1],axis=3)],\n",
    "                    #X_train,\n",
    "                    [np.delete(X_train,[1,2],axis=3),\n",
    "                     np.delete(X_train,[0,2],axis=3),\n",
    "                     np.delete(X_train,[0,1],axis=3)],\n",
    "                    epochs = 10,\n",
    "                    validation_data = (\n",
    "                    [np.delete(X_val,[1,2],axis=3),\n",
    "                     np.delete(X_val,[0,2],axis=3),\n",
    "                     np.delete(X_val,[0,1],axis=3)],\n",
    "                    #X_val),\n",
    "                    [np.delete(X_val,[1,2],axis=3),\n",
    "                     np.delete(X_val,[0,2],axis=3),\n",
    "                     np.delete(X_val,[0,1],axis=3)]),\n",
    "                    batch_size = 512,\n",
    "                    callbacks = [\n",
    "                        tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 10, mode = \"min\")\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot loss vs epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history.history['loss'], label = 'train loss')\n",
    "#axes.set_yscale(value = \"log\")\n",
    "axes.plot(history.history['val_loss'], label = 'val loss')\n",
    "axes.legend(loc = \"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving/loading trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_models/teacher_sep26')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('saved_models/teacher_sep26')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodel.save('saved_models/qmodel_Oct3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 18, 14, 1)]       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 252)               0         \n",
      "                                                                 \n",
      " dense1 (QDense)             (None, 100)               25200     \n",
      "                                                                 \n",
      " QBN1 (QBatchNormalization)  (None, 100)               400       \n",
      "                                                                 \n",
      " relu1 (QActivation)         (None, 100)               0         \n",
      "                                                                 \n",
      " output (QDense)             (None, 1)                 100       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,700\n",
      "Trainable params: 25,500\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "qmodel = tf.keras.models.load_model('saved_models/qmodel_oct3')\n",
    "qmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed all datasets into the trained model to compute prediction outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = h5py.File('bkg/EphemeralZeroBias2018RunD_2.h5', 'r')\n",
    "X_test = np.stack((X_test['CaloRegions'][:500000].astype('float32'),\n",
    "                   X_test['EGBit'][:500000].astype('float32'),\n",
    "                   X_test['TauBit'][:500000].astype('float32')))\n",
    "X_test = np.moveaxis(X_test, 0, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_predict = qmodel.predict(np.delete(X_test,[1,2],axis=3))\n",
    "#X_train_predict = model.predict(X_train)\n",
    "#X_val_predict = model.predict(X_val)\n",
    "#X_test_predict = model.predict(X_test)\n",
    "MC_predict = []\n",
    "for i in range(len(MC)):\n",
    "    MC_predict.append(qmodel.predict(np.delete(MC[i],[1,2],axis=3)))\n",
    "    #MC_predict.append(model.predict(MC[i]))\n",
    "    #MC_predict.append(model.predict(MC_masked[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_predict = model.predict([np.delete(X_test,[1,2],axis=3),\n",
    "                                     np.delete(X_test,[0,2],axis=3),\n",
    "                                     np.delete(X_test,[0,1],axis=3)])\n",
    "MC_predict = []\n",
    "for i in range(len(MC)):\n",
    "    MC_predict.append(model.predict([np.delete(MC_masked[i],[1,2],axis=3),\n",
    "                                          np.delete(MC_masked[i],[0,2],axis=3),\n",
    "                                          np.delete(MC_masked[i],[0,1],axis=3)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define loss function to use for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_for_pred(y_true, y_pred, choice):\n",
    "    #MSE\n",
    "    if choice == 0:\n",
    "        loss = np.mean((y_true - y_pred)**2, axis = (1, 2, 3))\n",
    "        return loss\n",
    "    \n",
    "    #MSE for de-noising model\n",
    "    if choice == 1:\n",
    "        loss = np.mean(y_pred**2, axis = (1, 2, 3))\n",
    "        return loss\n",
    "    \n",
    "    #VAE radius loss\n",
    "    if choice == 2:\n",
    "        loss = np.sqrt(np.sum(y_pred**2, axis = 1))\n",
    "        return loss\n",
    "    \n",
    "    #VAE KL loss\n",
    "    if choice == 3:\n",
    "        loss = -0.5 * np.sum(1.0 + y_pred - y_true**2 - np.exp(y_pred), axis = 1)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute loss for all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_choice = 0\n",
    "\n",
    "#X_test_loss = custom_loss_for_pred(np.delete(X_test,[1,2],axis=3), X_test_predict, loss_choice)\n",
    "#X_test_loss = custom_loss_for_pred(np.delete(X_test,[1,2],axis=3), X_test_predict[0], loss_choice)+custom_loss_for_pred(np.delete(X_test,[0,2],axis=3), X_test_predict[1], loss_choice)+custom_loss_for_pred(np.delete(X_test,[0,1],axis=3), X_test_predict[2], loss_choice)\n",
    "#X_test_loss = custom_loss_for_pred(np.delete(X_test,[0,2],axis=3), X_test_predict[1], loss_choice)+custom_loss_for_pred(np.delete(X_test,[0,1],axis=3), X_test_predict[2], loss_choice)\n",
    "X_train_loss = custom_loss_for_pred(X_train, X_train_predict, loss_choice)\n",
    "X_val_loss = custom_loss_for_pred(X_val, X_val_predict, loss_choice)\n",
    "X_test_loss = custom_loss_for_pred(X_test, X_test_predict, loss_choice)\n",
    "\n",
    "MC_loss = []\n",
    "for i in range(len(MC)):\n",
    "    #MC_loss.append(custom_loss_for_pred(np.delete(MC_masked[i],[1,2],axis=3), MC_predict[i][0], loss_choice)+custom_loss_for_pred(np.delete(MC_masked[i],[0,2],axis=3), MC_predict[i][1], loss_choice)+custom_loss_for_pred(np.delete(MC_masked[i],[0,1],axis=3), MC_predict[i][2], loss_choice))\n",
    "    #MC_loss.append(custom_loss_for_pred(np.delete(MC_masked[i],[0,2],axis=3), MC_predict[i][1], loss_choice)+custom_loss_for_pred(np.delete(MC_masked[i],[0,1],axis=3), MC_predict[i][2], loss_choice))\n",
    "    MC_loss.append(custom_loss_for_pred(np.delete(MC[i],[1,2],axis=3), MC_predict[i], loss_choice))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot loss distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 20\n",
    "rmin = 0\n",
    "rmax = 100\n",
    "plt.hist(X_test_loss, density = 1, bins = nbins, alpha = 0.3, label = 'test (ZeroBias)', range = (rmin, rmax), log = True)\n",
    "#plt.hist(MC_ZB_loss[0], density = 1, bins = nbins, label = 'QCD', alpha = 0.1, histtype = 'stepfilled', range = (rmin, rmax))\n",
    "for i in range(3,7):\n",
    "    plt.hist(MC_loss[i], density = 1, bins = nbins, label = MC_files[i], histtype = 'step', range = (rmin, rmax))\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel(\"Anomaly score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between original and reconstructed inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_ZB = True\n",
    "#show_ZB = False\n",
    "n = 6\n",
    "for i in range(1180,1190):\n",
    "    fig, ax = plt.subplots(figsize = (17,17))\n",
    "    if show_ZB == True:\n",
    "        print('ZB test\\nloss = ' + str(X_test_loss[i]))\n",
    "    else:\n",
    "        print(str(MC_files[n]) + '\\nloss = ' + str(MC_loss[n][i]))\n",
    "    ax = plt.subplot(3, 3, 1)\n",
    "    if show_ZB == True:\n",
    "        ax = sns.heatmap(X_test[i,:,:,0].reshape(18, 14), vmin = 0, vmax = X_test[i,:,:,0].max(), cmap = \"Greens\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    else:\n",
    "        ax = sns.heatmap(MC[n][i,:,:,0].reshape(18, 14), vmin = 0, vmax = MC[n][i,:,:,0].max(), cmap = \"Greens\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title('Original')\n",
    "    \n",
    "    ax = plt.subplot(3, 3, 2)\n",
    "    if show_ZB == True:\n",
    "        ax = sns.heatmap(X_test_predict[i,:,:,0].reshape(18, 14), vmin = 0, vmax = X_test[i,:,:,0].max(), cmap = \"Greens\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    else:\n",
    "        ax = sns.heatmap(MC_predict[n][i,:,:,0].reshape(18, 14), vmin = 0, vmax = MC[n][i,:,:,0].max(), cmap = \"Greens\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title('Reconstructed')\n",
    "    \n",
    "    ax = plt.subplot(3, 3, 3)\n",
    "    if show_ZB == True:\n",
    "        ax = sns.heatmap(np.absolute(X_test_predict[i,:,:,0] - X_test[i,:,:,0]).reshape(18, 14), vmin = 0, vmax = X_test[i,:,:,0].max(), cmap = \"Greens\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    else:\n",
    "        ax = sns.heatmap(np.absolute(MC_predict[n][i,:,:,0] - MC[n][i,:,:,0]).reshape(18, 14), vmin = 0, vmax = MC[n][i,:,:,0].max(), cmap = \"Greens\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title('abs(original-reconstructed)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_ZB = True\n",
    "show_ZB = False\n",
    "n = 3\n",
    "for i in range(1180,1183):\n",
    "    fig, ax = plt.subplots(figsize = (12,12))\n",
    "    if show_ZB == True:\n",
    "        print('ZB test\\nloss = ' + str(X_test_loss[i]))\n",
    "    else:\n",
    "        print(str(MC_files[n]) + '\\nloss = ' + str(MC_loss[n][i]))\n",
    "    ax = plt.subplot(3, 3, 1)\n",
    "    if show_ZB == True:\n",
    "        ax = sns.heatmap(X_test[i,:,:,0].reshape(18, 14), vmin = 0, vmax = X_test[i,:,:,0].max(), cmap = \"Greens\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    else:\n",
    "        ax = sns.heatmap(MC_masked[n][i,:,:,0].reshape(18, 14), vmin = 0, vmax = MC_masked[n][i,:,:,0].max(), cmap = \"Greens\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title('Original: No-bit channel')\n",
    "    \n",
    "    ax = plt.subplot(3, 3, 2)\n",
    "    if show_ZB == True:\n",
    "        ax = sns.heatmap(X_test[i,:,:,1].reshape(18, 14), vmin = 0, vmax = X_test[i,:,:,1].max(), cmap = \"Greens\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    else:\n",
    "        ax = sns.heatmap(MC_masked[n][i,:,:,1].reshape(18, 14), vmin = 0, vmax = MC_masked[n][i,:,:,1].max(), cmap = \"Greens\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title('Original: EG channel')\n",
    "    \n",
    "    ax = plt.subplot(3, 3, 3)\n",
    "    if show_ZB == True:\n",
    "        ax = sns.heatmap(X_test[i,:,:,2].reshape(18, 14), vmin = 0, vmax = X_test[i,:,:,2].max(), cmap = \"Greens\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    else:\n",
    "        ax = sns.heatmap(MC_masked[n][i,:,:,2].reshape(18, 14), vmin = 0, vmax = MC_masked[n][i,:,:,2].max(), cmap = \"Greens\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title('Original: Tau channel')\n",
    "    \n",
    "    ax = plt.subplot(3, 3, 4)\n",
    "    if show_ZB == True:\n",
    "        ax = sns.heatmap(X_test_predict[0][i,:,:,0].reshape(18, 14), vmin = 0, vmax = X_test[i,:,:,0].max(), cmap = \"Greens\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    else:\n",
    "        ax = sns.heatmap(MC_predict[n][0][i,:,:,0].reshape(18, 14), vmin = 0, vmax = MC_masked[n][i,:,:,0].max(), cmap = \"Greens\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title('Reconstructed: No-bit channel')\n",
    "    \n",
    "    ax = plt.subplot(3, 3, 5)\n",
    "    if show_ZB == True:\n",
    "        ax = sns.heatmap(X_test_predict[1][i,:,:,0].reshape(18, 14), vmin = 0, vmax = X_test[i,:,:,1].max(), cmap = \"Greens\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    else:\n",
    "        ax = sns.heatmap(MC_predict[n][1][i,:,:,0].reshape(18, 14), vmin = 0, vmax = MC_masked[n][i,:,:,1].max(), cmap = \"Greens\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title('Reconstructed: EG channel')\n",
    "    \n",
    "    ax = plt.subplot(3, 3, 6)\n",
    "    if show_ZB == True:\n",
    "        ax = sns.heatmap(X_test_predict[2][i,:,:,0].reshape(18, 14), vmin = 0, vmax = X_test[i,:,:,2].max(), cmap = \"Greens\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    else:\n",
    "        ax = sns.heatmap(MC_predict[n][2][i,:,:,0].reshape(18, 14), vmin = 0, vmax = MC_masked[n][i,:,:,2].max(), cmap = \"Greens\", cbar_kws = {'label': 'ET (GeV)'})\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title('Reconstructed: Tau channel')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Distillation (+ quantizing with QKeras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qkeras import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct student model without quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in = layers.Input(shape = (18, 14, 1), name = \"input\")\n",
    "x = layers.Flatten(name = \"flatten\")(x_in)\n",
    "x = layers.Dense(60, use_bias = False, name = \"dense1\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu', name = \"relu2\")(x)\n",
    "x = layers.Dense(80, use_bias = False, name = \"dense2\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu', name = \"relu3\")(x)\n",
    "x = layers.Dense(1, name = \"dense3\")(x)\n",
    "#x = layers.Activation('relu', name = \"output\")(x)\n",
    "\n",
    "qmodel = tf.keras.models.Model(x_in, x)\n",
    "qmodel.summary()\n",
    "qmodel.compile(optimizer = 'adam', loss = 'mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct student model with pre-defined quantization configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For quantization-aware training\n",
    "x_in = layers.Input(shape = (18, 14, 1), name = 'input')\n",
    "x = layers.Flatten(name = 'flatten')(x_in)\n",
    "x = QDense(100, kernel_quantizer = quantized_bits(6, 0, 1, alpha=1.0),\n",
    "           use_bias = False, name = 'dense1')(x)\n",
    "#x = QBatchNormalization(name = 'QBN1')(x)\n",
    "x = QBatchNormalization(beta_quantizer=quantized_bits(10, 2, 1, alpha='auto'),\n",
    "                        gamma_quantizer=quantized_bits(10, 2, 1, alpha='auto'),\n",
    "                        mean_quantizer=quantized_bits(10, 2, 1, alpha='auto'),\n",
    "                        variance_quantizer=quantized_bits(10, 2, 1, alpha='auto'),\n",
    "                        name = 'QBN1')(x)\n",
    "x = QActivation('quantized_relu(5, 0)', name = 'relu1')(x)\n",
    "x = QDense(1, kernel_quantizer = quantized_bits(2, 0, 1, alpha=1.0),\n",
    "           use_bias = False, name = 'output')(x)\n",
    "\n",
    "qmodel = tf.keras.models.Model(x_in, x)\n",
    "qmodel.summary()\n",
    "qmodel.compile(optimizer = 'adam', loss = 'mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the student model with knowledge distilled from a pre-trained teacher model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_student = qmodel.fit(X_train, X_train_loss,\n",
    "                                epochs = 60,\n",
    "                                validation_data = (X_val, X_val_loss),\n",
    "                                batch_size = 256,\n",
    "                                callbacks = [\n",
    "                                    #tensorboard_callback,\n",
    "                                    tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 200, mode = \"min\")\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot loss vs epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history_student.history['loss'], label = 'train loss')\n",
    "#axes.set_yscale(value = \"log\")\n",
    "axes.plot(history_student.history['val_loss'], label = 'val loss')\n",
    "axes.legend(loc = \"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed all datasets into the trained model to compute prediction outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_predict_qmodel = qmodel.predict(X_train)\n",
    "X_test_predict_qmodel = qmodel.predict(X_test)\n",
    "MC_predict_qmodel = []\n",
    "for i in range(len(MC)):\n",
    "    MC_predict_qmodel.append(qmodel.predict(MC[i][:,:,:,0].reshape(-1,18,14,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot loss distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nbins = 20\n",
    "rmin = 0\n",
    "rmax = 27\n",
    "#plt.hist(X_train_predict_qmodel, density = 1, bins = nbins, alpha = 0.3, label = 'train (ZeroBias)', range = (rmin, rmax), log = True)\n",
    "plt.hist(X_test_predict, density = 1, bins = nbins, alpha = 0.3, label = 'test (ZeroBias)', range = (rmin, rmax), log = True)\n",
    "#plt.hist(MC_predict_qmodel[0], density = 1, bins = nbins, label = 'QCD', alpha = 0.1, histtype = 'stepfilled', range = (rmin, rmax))\n",
    "#plt.hist(MC_predict_qmodel[1], density = 1, bins = nbins, label = 'SingleNu', alpha = 0.1, histtype = 'stepfilled', range = (rmin, rmax))\n",
    "plt.hist(MC_predict[3], density = 1, bins = nbins, label = 'H->tautau', histtype = 'step', range = (rmin, rmax))\n",
    "plt.hist(MC_predict[4], density = 1, bins = nbins, label = 'SM HH->4b', histtype = 'step', range = (rmin, rmax))\n",
    "plt.hist(MC_predict[5], density = 1, bins = nbins, label = 'TTbar', histtype = 'step', range = (rmin, rmax))\n",
    "plt.hist(MC_predict[6], density = 1, bins = nbins, label = 'H->aa->4b', histtype = 'step', range = (rmin, rmax))\n",
    "#plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "#plt.legend(loc='center left', bbox_to_anchor=(0.57, 0.5))\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel(\"loss\")\n",
    "#plt.xticks(np.arange(rmin, rmax, step = 0.0002))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Distillation (+ quantizing with AutoQKeras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qkeras import *\n",
    "from qkeras.autoqkeras import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_for_autoqk(y_true, y_pred):\n",
    "    loss = 10 - tf.reduce_mean(tf.square(y_true - y_pred), axis = -1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_in = layers.Input(shape=(18,14,1),name=\"In\")\n",
    "x = layers.Flatten(name=\"Flatten\")(x_in)\n",
    "x = layers.Dense(40,use_bias=False,name=\"Dense_1\")(x)\n",
    "x = QBatchNormalization(name=\"QBN_1\")(x)\n",
    "x = layers.Activation('relu',name=\"Activation_1\")(x)\n",
    "x = layers.Dense(60,use_bias=False,name=\"Dense_2\")(x)\n",
    "x = QBatchNormalization(name=\"QBN_2\")(x)\n",
    "x = layers.Activation('relu',name=\"Activation_2\")(x)\n",
    "x = layers.Dense(1,use_bias=False,name=\"Out\")(x)\n",
    "\n",
    "qmodel_original = tf.keras.models.Model(x_in, x)\n",
    "qmodel_original.summary()\n",
    "qmodel_original.compile(optimizer = 'adam', loss = 'mse', metrics = [metric_for_autoqk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = {\n",
    "        \"kernel\": {\n",
    "                \"quantized_bits(2,0,1,alpha=1.0)\": 2,\n",
    "                \"quantized_bits(2,1,1,alpha=1.0)\": 2,\n",
    "                \"quantized_bits(3,0,1,alpha=1.0)\": 3,\n",
    "                \"quantized_bits(3,1,1,alpha=1.0)\": 3,\n",
    "                \"quantized_bits(4,0,1,alpha=1.0)\": 4,\n",
    "                \"quantized_bits(4,1,1,alpha=1.0)\": 4,\n",
    "                \"quantized_bits(5,0,1,alpha=1.0)\": 5,\n",
    "                \"quantized_bits(5,1,1,alpha=1.0)\": 5\n",
    "        },\n",
    "        \"activation\": {\n",
    "                \"quantized_relu(2,0)\": 2,\n",
    "                \"quantized_relu(2,1)\": 2,\n",
    "                \"quantized_relu(3,0)\": 3,\n",
    "                \"quantized_relu(3,1)\": 3,\n",
    "                \"quantized_relu(4,0)\": 4,\n",
    "                \"quantized_relu(4,1)\": 4,\n",
    "                \"quantized_relu(5,0)\": 5,\n",
    "                \"quantized_relu(5,1)\": 5\n",
    "        }\n",
    "}\n",
    "\n",
    "limit = {\n",
    "    \"Dense\": [5,5,5], # format for Dense is max bits for [kernel,bias,activation] \n",
    "    \"Activation\": [5] # format for Activation is max bits for [activation]\n",
    "    #\"BatchNormalization\": []\n",
    "}\n",
    "\n",
    "goal = {\n",
    "    \"type\": \"bits\", # energy, bits\n",
    "    \"params\": {\n",
    "        \"delta_p\": 8.0,\n",
    "        \"delta_n\": 8.0,\n",
    "        \"rate\": 2.0,\n",
    "        \"stress\": 1.0,\n",
    "        #\"process\": \"horowitz\",\n",
    "        #\"parameters_on_memory\": [\"sram\", \"sram\"],\n",
    "        #\"activations_on_memory\": [\"sram\", \"sram\"],\n",
    "        #\"rd_wr_on_io\": [False, False],\n",
    "        #\"min_sram_size\": [0, 0],\n",
    "        #\"source_quantizers\": [\"quantized_bits(bits=10,integer=10,symmetric=0,keep_negative=False)\"],\n",
    "        #\"reference_internal\": \"int8\",\n",
    "        #\"reference_accumulator\": \"int32\"\n",
    "        \"input_bits\": 8,\n",
    "        \"output_bits\": 8,\n",
    "        \"ref_bits\": 8,\n",
    "        \"config\": {\n",
    "            \"default\": [\"parameters\", \"activations\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "run_config = {\n",
    "  \"output_dir\": \"run_config\",\n",
    "  \"goal\": goal,\n",
    "  \"quantization_config\": quantization_config,\n",
    "  \"learning_rate_optimizer\": False, # False since still experimental\n",
    "  \"transfer_weights\": False, # False for the #filters/neurons to float\n",
    "  \"mode\": \"hyperband\", # random/bayesian/hyperband\n",
    "  \"seed\": 123,\n",
    "  \"limit\": limit,\n",
    "  \"tune_filters\": \"none\", # layer/block/none(no filter tunning at all)\n",
    "  \"tune_filters_exceptions\": \"\",\n",
    "  #\"layer_indexes\": range(1 + 1, len(qmodel_original.layers))\n",
    "  \"layer_indexes\": (2,4,5,7,8)\n",
    "}\n",
    "\n",
    "print(\"quantizing layers:\", [qmodel_original.layers[i].name for i in run_config[\"layer_indexes\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "autoqk = AutoQKeras(qmodel_original, metrics=[metric_for_autoqk], custom_objects={}, **run_config)\n",
    "autoqk.fit(X_train, X_train_loss, validation_data=(X_val, X_val_loss), batch_size=128, epochs=8)\n",
    "# i = log(reference_size / trial_size) / log(rate)\n",
    "# delta = i * ( (i < 0) * delta_n + (i >= 0) * delta_p )\n",
    "# objective to maximize in the search is\n",
    "# adjusted score =  metric * (1 + delta), as formulated in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodel = autoqk.get_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodel.save_weights(\"qmodel1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodel.load_weights(\"qmodel1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "qmodel.compile(optimizer='adam', loss=\"mse\")\n",
    "history_qmodel = qmodel.fit(X_train, X_train_loss, epochs=40, batch_size=256, validation_data=(X_val, X_val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "axes.plot(history_qmodel.history['loss'], label = 'train loss')\n",
    "#axes.set_yscale(value = \"log\")\n",
    "axes.plot(history_qmodel.history['val_loss'], label = 'val loss')\n",
    "axes.legend(loc = \"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_predict_qmodel = qmodel.predict(X_train)\n",
    "X_test_predict_qmodel = qmodel.predict(X_test)\n",
    "MC_predict_qmodel = []\n",
    "for i in range(len(MC)):\n",
    "    MC_predict_qmodel.append(qmodel.predict(np.delete(MC[i],[1,2],axis=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 20\n",
    "rmin = 0\n",
    "rmax = 18\n",
    "#plt.hist(X_train_predict_qmodel, density = 1, bins = nbins, alpha = 0.3, label = 'train (ZeroBias)', range = (rmin, rmax), log = True)\n",
    "plt.hist(X_test_predict_qmodel, density = 1, bins = nbins, alpha = 0.3, label = 'test (ZeroBias)', range = (rmin, rmax), log = True)\n",
    "#plt.hist(MC_predict_qmodel[0], density = 1, bins = nbins, label = 'QCD', alpha = 0.1, histtype = 'stepfilled', range = (rmin, rmax))\n",
    "#plt.hist(MC_predict_qmodel[1], density = 1, bins = nbins, label = 'SingleNu', alpha = 0.1, histtype = 'stepfilled', range = (rmin, rmax))\n",
    "plt.hist(MC_predict_qmodel[3], density = 1, bins = nbins, label = 'H->tautau', histtype = 'step', range = (rmin, rmax))\n",
    "plt.hist(MC_predict_qmodel[4], density = 1, bins = nbins, label = 'SM HH->4b', histtype = 'step', range = (rmin, rmax))\n",
    "plt.hist(MC_predict_qmodel[5], density = 1, bins = nbins, label = 'TTbar', histtype = 'step', range = (rmin, rmax))\n",
    "plt.hist(MC_predict_qmodel[6], density = 1, bins = nbins, label = 'H->aa->4b', histtype = 'step', range = (rmin, rmax))\n",
    "#plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "#plt.legend(loc='center left', bbox_to_anchor=(0.57, 0.5))\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel(\"loss\")\n",
    "#plt.xticks(np.arange(rmin, rmax, step = 0.0002))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard (less useful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "rm -rf ./logs/\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = \"logs/fit\", histogram_freq = 1)\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning labels and arranging for ROC plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline\n",
    "#Assuming only the mean ZB is learned\n",
    "#Take mean ZB as outputs no matter what inputs are\n",
    "#Classifier of baseline = MSE(inputs, ZeroBias_mean)\n",
    "ZeroBias_mean = np.mean(ZeroBias[:,:,:,0].reshape(-1,18,14,1), axis = 0)\n",
    "\n",
    "baseline_zb = np.mean((X_test[:,:,:,0].reshape(-1,18,14,1) - ZeroBias_mean)**2, axis = (1, 2))\n",
    "baseline_mc = []\n",
    "for i in range(len(MC)):\n",
    "    baseline_mc.append(np.mean((MC[i][:,:,:,0].reshape(-1,18,14,1) - ZeroBias_mean)**2, axis = (1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign labels for various signals (y = 1) and backgrounds (y = 0)\n",
    "Y_zb = np.zeros((X_test.shape[0], 1))\n",
    "Y_mc = []\n",
    "for i in range(len(MC)):\n",
    "    Y_mc.append(np.ones((MC[i].shape[0], 1)))\n",
    "\n",
    "#Concatenate datasets to make ROC curves, i.e. QCD/SingleNu/signals vs ZB\n",
    "\n",
    "#True labels\n",
    "Y_true = []\n",
    "#Baseline scores\n",
    "Y_baseline = []\n",
    "#Model scores\n",
    "Y_model = []\n",
    "Y_qmodel = []\n",
    "\n",
    "for i in range(len(MC)):\n",
    "    Y_true.append(np.concatenate((Y_mc[i], Y_zb)))\n",
    "    Y_baseline.append(np.concatenate((baseline_mc[i], baseline_zb)))\n",
    "    #Y_model.append(np.concatenate((MC_loss[i], X_test_loss)))\n",
    "    Y_qmodel.append(np.concatenate((MC_predict[i], X_test_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (13, 13))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "fpr_baseline = []\n",
    "tpr_baseline = []\n",
    "thresholds_baseline = []\n",
    "roc_auc_baseline = []\n",
    "for i in range(len(MC)):\n",
    "    fpr_baseline.append(np.empty((Y_true[i].shape[0],1)))\n",
    "    tpr_baseline.append(np.empty((Y_true[i].shape[0],1)))\n",
    "    thresholds_baseline.append(np.empty((Y_true[i].shape[0],1)))\n",
    "    roc_auc_baseline.append(np.empty((Y_true[i].shape[0],1)))\n",
    "    fpr_baseline[i], tpr_baseline[i], thresholds_baseline[i] = roc_curve(Y_true[i], Y_baseline[i])\n",
    "    roc_auc_baseline[i] = auc(fpr_baseline[i], tpr_baseline[i])\n",
    "    fpr_baseline[i] *= 28.61\n",
    "    if i == 0:\n",
    "        print(1)\n",
    "        #axes.plot(fpr_model[i], tpr_model[i], linestyle = '--', color = 'r', lw = 1, label = MC_files[i] + ' (AUC = %.8f)' % (roc_auc_model[i]))\n",
    "    if i == 1 or i == 2:\n",
    "        print(1)\n",
    "        #axes.plot(fpr_model[i], tpr_model[i], linestyle = ':', lw = 1, label = MC_files[i] + ' (AUC = %.8f)' % (roc_auc_model[i]))\n",
    "    if i == 3:\n",
    "        #axes.plot(fpr_model[3], tpr_model[3], linestyle = '--', lw = 1, color = 'blue', label = 'SM H->2tau (AUC = %.5f)' % (roc_auc_model[3]))\n",
    "        axes.plot(fpr_baseline[3], tpr_baseline[3], linestyle = '-', lw = 1.5, color = 'green', label = 'H->2Tau (AUC = %.5f)' % (roc_auc_baseline[3]))\n",
    "    if i == 4:\n",
    "        #axes.plot(fpr_model[4], tpr_model[4], linestyle = '--', lw = 1, color = 'orange', label = 'SM HH->4b (AUC = %.5f)' % (roc_auc_model[4]))\n",
    "        axes.plot(fpr_baseline[4], tpr_baseline[4], linestyle = '-', lw = 1.5, color = 'red', label = 'SM HH->4b (AUC = %.5f)' % (roc_auc_baseline[4]))\n",
    "    if i == 5:\n",
    "        #axes.plot(fpr_model[5], tpr_model[5], linestyle = '--', lw = 1, color = 'green', label = 'H->2LongLived->4b (AUC = %.5f)' % (roc_auc_model[5]))\n",
    "        axes.plot(fpr_baseline[5], tpr_baseline[5], linestyle = '-', lw = 1.5, color = 'blue', label = 'TTbar (AUC = %.5f)' % (roc_auc_baseline[5]))\n",
    "    if i == 6:\n",
    "        #axes.plot(fpr_model[6], tpr_model[6], linestyle = '--', lw = 1, color = 'red', label = 'TTbar (AUC = %.5f)' % (roc_auc_model[6]))\n",
    "        axes.plot(fpr_baseline[6], tpr_baseline[6], linestyle = '-', lw = 1.5, color = 'orange', label = 'H->aa->4b (AUC = %.5f)' % (roc_auc_baseline[6]))\n",
    "axes.plot([0.005, 0.005], [0, 1], linestyle = '--', lw = 1, color = 'black', label = 'FPR = 0.0175% ~ (5 kHz)/(ZeroBias 28.61 MHz)')\n",
    "axes.set_xlim([0.0002861, 28.61])\n",
    "axes.set_ylim([0.000001, 1.0])\n",
    "axes.set_xscale(value = \"log\")\n",
    "axes.set_yscale(value = \"log\")\n",
    "axes.set_xlabel('Trigger Rate (MHz)',size=15)\n",
    "axes.set_ylabel('Signal Efficiency',size=15)\n",
    "axes.set_title('Baseline (energy based)',size=15)\n",
    "axes.legend(loc='center left', bbox_to_anchor = (0.5, 0.5),fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher model ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (13, 13))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "fpr_model = []\n",
    "tpr_model = []\n",
    "thresholds_model = []\n",
    "roc_auc_model = []\n",
    "for i in range(len(MC)):\n",
    "    fpr_model.append(np.empty((Y_true[i].shape[0],1)))\n",
    "    tpr_model.append(np.empty((Y_true[i].shape[0],1)))\n",
    "    thresholds_model.append(np.empty((Y_true[i].shape[0],1)))\n",
    "    roc_auc_model.append(np.empty((Y_true[i].shape[0],1)))\n",
    "    fpr_model[i], tpr_model[i], thresholds_model[i] = roc_curve(Y_true[i], Y_model[i])\n",
    "    roc_auc_model[i] = auc(fpr_model[i], tpr_model[i])\n",
    "    fpr_model[i] *= 28.61\n",
    "    if i == 0:\n",
    "        print(1)\n",
    "        #axes.plot(fpr_model[i], tpr_model[i], linestyle = '--', color = 'r', lw = 1, label = MC_files[i] + ' (AUC = %.8f)' % (roc_auc_model[i]))\n",
    "    if i == 1 or i == 2:\n",
    "        print(1)\n",
    "        #axes.plot(fpr_model[i], tpr_model[i], linestyle = ':', lw = 1, label = MC_files[i] + ' (AUC = %.8f)' % (roc_auc_model[i]))\n",
    "    if i == 3:\n",
    "        #axes.plot(fpr_model[3], tpr_model[3], linestyle = '--', lw = 1, color = 'blue', label = 'SM H->2tau (AUC = %.5f)' % (roc_auc_model[3]))\n",
    "        axes.plot(fpr_model[3], tpr_model[3], linestyle = '-', lw = 1.5, color = 'green', label = 'H->tautau (AUC = %.5f)' % (roc_auc_model[3]))\n",
    "    if i == 4:\n",
    "        #axes.plot(fpr_model[4], tpr_model[4], linestyle = '--', lw = 1, color = 'orange', label = 'SM HH->4b (AUC = %.5f)' % (roc_auc_model[4]))\n",
    "        axes.plot(fpr_model[4], tpr_model[4], linestyle = '-', lw = 1.5, color = 'red', label = 'SM HH->4b (AUC = %.5f)' % (roc_auc_model[4]))\n",
    "    if i == 5:\n",
    "        #axes.plot(fpr_model[5], tpr_model[5], linestyle = '--', lw = 1, color = 'green', label = 'H->2LongLived->4b (AUC = %.5f)' % (roc_auc_model[5]))\n",
    "        axes.plot(fpr_model[5], tpr_model[5], linestyle = '-', lw = 1.5, color = 'blue', label = 'TTbar (AUC = %.5f)' % (roc_auc_model[5]))\n",
    "    if i == 6:\n",
    "        #axes.plot(fpr_model[6], tpr_model[6], linestyle = '--', lw = 1, color = 'red', label = 'TTbar (AUC = %.5f)' % (roc_auc_model[6]))\n",
    "        axes.plot(fpr_model[6], tpr_model[6], linestyle = '-', lw = 1.5, color = 'orange', label = 'H->aa->4b (AUC = %.5f)' % (roc_auc_model[6]))\n",
    "axes.plot([0.005, 0.005], [0, 1], linestyle = '--', lw = 1, color = 'black', label = 'Trigger rate = 5 kHz')\n",
    "axes.set_xlim([0.0002861, 28.61])\n",
    "axes.set_ylim([0.000001, 1.0])\n",
    "axes.set_xscale(value = \"log\")\n",
    "axes.set_yscale(value = \"log\")\n",
    "axes.set_xlabel('Trigger Rate (MHz)',size=15)\n",
    "axes.set_ylabel('Signal Efficiency',size=15)\n",
    "axes.set_title('Teacher model',size=15)\n",
    "axes.legend(loc='center left', bbox_to_anchor = (0.3, 0.5),fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student model ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x936 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (13, 13))\n",
    "axes = plt.subplot(2, 2, 1)\n",
    "fpr_qmodel = []\n",
    "tpr_qmodel = []\n",
    "thresholds_qmodel = []\n",
    "roc_auc_qmodel = []\n",
    "for i in range(len(MC)):\n",
    "    fpr_qmodel.append(np.empty((Y_true[i].shape[0],1)))\n",
    "    tpr_qmodel.append(np.empty((Y_true[i].shape[0],1)))\n",
    "    thresholds_qmodel.append(np.empty((Y_true[i].shape[0],1)))\n",
    "    roc_auc_qmodel.append(np.empty((Y_true[i].shape[0],1)))\n",
    "    fpr_qmodel[i], tpr_qmodel[i], thresholds_qmodel[i] = roc_curve(Y_true[i], Y_qmodel[i])\n",
    "    roc_auc_qmodel[i] = auc(fpr_qmodel[i], tpr_qmodel[i])\n",
    "    fpr_qmodel[i] *= 28.61\n",
    "    if i == 0:\n",
    "        print(1)\n",
    "        #axes.plot(fpr_qmodel[i], tpr_qmodel[i], linestyle = '--', color = 'r', lw = 1, label = MC_files[i] + ' (AUC = %.8f)' % (roc_auc_qmodel[i]))\n",
    "    if i == 1 or i == 2:\n",
    "        print(1)\n",
    "        #axes.plot(fpr_qmodel[i], tpr_qmodel[i], linestyle = ':', lw = 1, label = MC_files[i] + ' (AUC = %.8f)' % (roc_auc_qmodel[i]))\n",
    "    if i == 3:\n",
    "        #axes.plot(fpr_qmodel[3], tpr_qmodel[3], linestyle = '--', lw = 1, color = 'blue', label = 'SM H->2tau (AUC = %.5f)' % (roc_auc_qmodel[3]))\n",
    "        axes.plot(fpr_qmodel[3], tpr_qmodel[3], linestyle = '-', lw = 1.5, color = 'green', label = 'H->tautau (AUC = %.5f)' % (roc_auc_qmodel[3]))\n",
    "    if i == 4:\n",
    "        #axes.plot(fpr_qmodel[4], tpr_qmodel[4], linestyle = '--', lw = 1, color = 'orange', label = 'SM HH->4b (AUC = %.5f)' % (roc_auc_qmodel[4]))\n",
    "        axes.plot(fpr_qmodel[4], tpr_qmodel[4], linestyle = '-', lw = 1.5, color = 'red', label = 'SM HH->4b (AUC = %.5f)' % (roc_auc_qmodel[4]))\n",
    "    if i == 5:\n",
    "        #axes.plot(fpr_qmodel[5], tpr_qmodel[5], linestyle = '--', lw = 1, color = 'green', label = 'H->2LongLived->4b (AUC = %.5f)' % (roc_auc_qmodel[5]))\n",
    "        axes.plot(fpr_qmodel[5], tpr_qmodel[5], linestyle = '-', lw = 1.5, color = 'blue', label = 'TTbar (AUC = %.5f)' % (roc_auc_qmodel[5]))\n",
    "    if i == 6:\n",
    "        #axes.plot(fpr_qmodel[6], tpr_qmodel[6], linestyle = '--', lw = 1, color = 'red', label = 'TTbar (AUC = %.5f)' % (roc_auc_qmodel[6]))\n",
    "        axes.plot(fpr_qmodel[6], tpr_qmodel[6], linestyle = '-', lw = 1.5, color = 'orange', label = 'H->aa->4b (AUC = %.5f)' % (roc_auc_qmodel[6]))\n",
    "axes.plot([0.005, 0.005], [0, 1], linestyle = '--', lw = 1, color = 'black', label = 'Trigger rate = 5 kHz')\n",
    "axes.set_xlim([0.0002861, 28.61])\n",
    "axes.set_ylim([0.000001, 1.0])\n",
    "axes.set_xscale(value = \"log\")\n",
    "axes.set_yscale(value = \"log\")\n",
    "axes.set_xlabel('Trigger Rate (MHz)',size=15)\n",
    "axes.set_ylabel('Signal Efficiency',size=15)\n",
    "axes.set_title('Quantized student model',size=15)\n",
    "axes.legend(loc='center left', bbox_to_anchor = (0.3, 0.5),fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_tpr_baseline = []\n",
    "table_tpr_model = []\n",
    "table_tpr_qmodel = []\n",
    "table_tpr_change = []\n",
    "for i in range(len(fpr_baseline)):\n",
    "    for j in range(len(fpr_baseline[i])):\n",
    "        if fpr_baseline[i][j] > 0.005:\n",
    "            table_tpr_baseline.append(tpr_baseline[i][j] * 100)\n",
    "            break\n",
    "    for j in range(len(fpr_model[i])):\n",
    "        if fpr_model[i][j] > 0.005:\n",
    "            table_tpr_model.append(tpr_model[i][j] * 100)\n",
    "            break\n",
    "    for j in range(len(fpr_qmodel[i])):\n",
    "        if fpr_qmodel[i][j] > 0.005:\n",
    "            table_tpr_qmodel.append(tpr_qmodel[i][j] * 100)\n",
    "            break\n",
    "\n",
    "#for i in range(len(MC)):\n",
    "    #table_tpr_change.append(100 * (table_tpr_model[i] - table_tpr_baseline[i])/table_tpr_baseline[i])\n",
    "\n",
    "MC_names = ['H->tautau','SM HH->4b','TTbar','H->aa->4b']\n",
    "table_tpr = pd.DataFrame({'Baseline': table_tpr_baseline[3:],\n",
    "                          'Model(Et)': table_tpr_model[3:],\n",
    "                          'QStudent(Et)': table_tpr_qmodel[3:]},\n",
    "                         index = MC_names)\n",
    "#table_tpr = table_tpr.sort_values(by = 'delta', ascending = False)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "table_tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_tpr_model = []\n",
    "table_tpr_model_bits = []\n",
    "table_tpr_change = []\n",
    "for i in range(len(fpr_model)):\n",
    "    for j in range(len(fpr_model[i])):\n",
    "        if fpr_model[i][j] > 0.000175:\n",
    "            table_tpr_model.append(np.round(tpr_model[i][j] * 100,3))\n",
    "            break\n",
    "    for j in range(len(fpr_model_bits[i])):\n",
    "        if fpr_model_bits[i][j] > 0.000175:\n",
    "            table_tpr_model_bits.append(np.round(tpr_model_bits[i][j] * 100,3))\n",
    "            break\n",
    "\n",
    "for i in range(len(MC)):\n",
    "    table_tpr_change.append(np.round(100 * (table_tpr_model_bits[i] - table_tpr_model[i])/table_tpr_model[i],3))\n",
    "    #table_tpr_change.append(-table_tpr_student[i] + table_tpr_qmodel[i])\n",
    "\n",
    "table_tpr = pd.DataFrame({'Model(Et)': table_tpr_model[3:],\n",
    "                          'Model(Et, Taubit)': table_tpr_model_bits[3:],\n",
    "                          '% more sensitive': table_tpr_change[3:]},\n",
    "                         index = MC_files[3:])\n",
    "#table_tpr = table_tpr.sort_values(by = 'delta(qDense, Dense)', ascending = False)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "table_tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
